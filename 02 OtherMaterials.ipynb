{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import scipy.sparse as sps\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD, SVDpp, NMF,KNNBaseline, BaselineOnly, CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 10,5\n",
    "sb.set_style(style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * CVX solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvxSolver(R_sa,M):\n",
    "    import cvxpy as cp\n",
    "    solver = 'cvx'\n",
    "    m, n = R_sa.shape   # Number of accounts and movies\n",
    "    O = np.array(R_sa != 0,dtype='float')   # Producing Observation matrix \n",
    "    k = M.shape[0]   # Number of features\n",
    "\n",
    "    X = cp.Variable(shape=(m, k))\n",
    "    constraint = [X >= 0]\n",
    "\n",
    "    obj = cp.Minimize(cp.norm(R_sa - cp.multiply(O,(X@M)),'fro'))\n",
    "\n",
    "    prob = cp.Problem(obj, constraint)\n",
    "    prob.solve()\n",
    "    A_hat = X.value\n",
    "    return A_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvxSolver_improved(R_sa, M):\n",
    "    import cvxpy as cp\n",
    "    m, n = R_sa.shape   # Number of accounts and movies\n",
    "    O = np.array(R_sa != 0,dtype='float')   # Producing Observation matrix \n",
    "    k = M.shape[0]   # Number of features\n",
    "    R = R_sa.astype(np.float32)  # rating matrix R\n",
    "    V = M.astype(np.float32)  # Known item feature matrix V\n",
    "    V_constant = cp.Parameter((k, n), value=V)\n",
    "\n",
    "    U = cp.Variable((m, k), nonneg=True)  # Ensures U is non-negative\n",
    "    objective = cp.Minimize(cp.norm(R - cp.multiply(O,(U @ V_constant)), 'fro') + 0.1 * cp.norm(U, 1))\n",
    "    problem = cp.Problem(objective)\n",
    "    result = problem.solve(solver=cp.SCS)\n",
    "    A = U.value\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * nimfa solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NimfaSolver(R_sa, k=4, max_iter = 100):\n",
    "    import nimfa\n",
    "    nmf = nimfa.Nmf(R_sa, rank=k, max_iter=max_iter)\n",
    "    nmf_fit = nmf()\n",
    "    A = nmf_fit.basis()\n",
    "    MN = nmf_fit.coef()\n",
    "    return np.asarray(A), np.asarray(MN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANNsolver(R_sa, M, n_iterations=1000):\n",
    "    import tensorflow as tf\n",
    "\n",
    "    R = R_sa.astype(np.float32)\n",
    "    M = M.astype(np.float32)\n",
    "\n",
    "    m, k, n = R.shape[0], M.shape[0], R.shape[1]\n",
    "\n",
    "    # Convert M to a TensorFlow constant\n",
    "    M_tensor = tf.constant(M, dtype=tf.float32)\n",
    "\n",
    "    # TensorFlow Dataset to manage batches of R\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(R)\n",
    "    dataset = dataset.batch(32)\n",
    "\n",
    "    # Create a trainable variable for X\n",
    "    X = tf.Variable(tf.random.normal([m, k], stddev=0.1), dtype=tf.float32)\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "    # Define the training step\n",
    "    @tf.function\n",
    "    def train_step(R_batch, indices):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Fetch the corresponding batch from X\n",
    "            X_batch = tf.gather(X, indices)\n",
    "            # Predict R for this batch using the corresponding X_batch and M\n",
    "            R_pred = tf.matmul(X_batch, M_tensor)\n",
    "            # Calculate the loss (Frobenius norm of the error)\n",
    "            loss = tf.reduce_mean(tf.square(R_batch - R_pred))\n",
    "        # Compute the gradients for X_batch\n",
    "        gradients = tape.gradient(loss, [X_batch])\n",
    "        # Apply gradients to the corresponding part of X\n",
    "        optimizer.apply_gradients([(tf.IndexedSlices(gradients[0], indices), X)])\n",
    "        return loss\n",
    "\n",
    "    # Training loop\n",
    "    epochs = n_iterations\n",
    "    for epoch in range(epochs):\n",
    "        for step, (R_batch) in enumerate(dataset):\n",
    "            # Create indices for the current batch\n",
    "            batch_indices = tf.range(step * 32, min((step + 1) * 32, m))\n",
    "            loss = train_step(R_batch, batch_indices)\n",
    "    #       if step % 100 == 0:\n",
    "    #             print(f\"Epoch {epoch}, Step {step}, Loss: {loss.numpy()}\")\n",
    "    return X.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_onto_face(A = 'array_like_matrix',l=0.9):\n",
    "    m,n = A.shape\n",
    "    P = np.zeros((m,n),dtype='float')\n",
    "    for i in range(m):\n",
    "        P[i] = np.array(A[i] >= l*A[i].max(),dtype='float')\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinarizingM(matrix,l=0.5):\n",
    "    normalized_matrix = normalize(matrix.T, axis=1, norm='l1')\n",
    "    a = project_onto_face(normalized_matrix,l)\n",
    "    return a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rn: reconstructing ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Demix(R_sa, A, A_B, MN):\n",
    "    R = []\n",
    "    Rn = []\n",
    "    for account_index in range(A.shape[0]):\n",
    "        account_ratings = []\n",
    "        T= np.zeros((A.shape[1],MN.shape[1]))\n",
    "        for k in range(A.shape[1]):\n",
    "            for j in range(MN.shape[1]):\n",
    "                T[k,j]=A[account_index,k]*MN[k,j]\n",
    "\n",
    "        P = np.reshape(A_B[account_index],(-1,1))*T\n",
    "        P = np.delete(P,np.where(A_B[account_index]==0),axis=0)\n",
    "        P = normalize(P, axis=0, norm='l1')\n",
    "        \n",
    "        for i in range(P.shape[0]):\n",
    "            account_ratings.append(R_sa[account_index]*P[i])\n",
    "        R.append(np.round(account_ratings,1))\n",
    "        for u in range(len(R[account_index])):\n",
    "            Rn.append(R[account_index][u])\n",
    "    return np.array(Rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decompose(R_sa, A, A_B):\n",
    "    '''\n",
    "    To reconstruct shared ratings based on account membership\n",
    "    '''\n",
    "    p=0\n",
    "    P=[]\n",
    "    RrN=[]\n",
    "    \n",
    "    m = A.shape[0]\n",
    "    for i in range(m):\n",
    "        p = A[i]*A_B[i]\n",
    "        p = p[p !=0]\n",
    "        p = normalize(np.reshape(p,(-1,1)),axis=0,norm='l1')\n",
    "        RrN.append(np.round(p * R_sa[i]))\n",
    "        P.append(p)\n",
    "    Rn=[]\n",
    "    for i in range(m):\n",
    "        for u in range(len(RrN[i])):\n",
    "            Rn.append(RrN[i][u])\n",
    "    return np.array(Rn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with movie features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decompose2(R_sa, A, A_B):\n",
    "    p=0\n",
    "    P=[]\n",
    "    RrN=[]\n",
    "    \n",
    "    m = A.shape[0]\n",
    "    for i in range(m):\n",
    "        p = A[i]*A_B[i]\n",
    "        p = p[p !=0]\n",
    "        p = p * MN\n",
    "        p = normalize(p,axis=0,norm='l1')\n",
    "        RrN.append(np.round(p * R_sa[i]))\n",
    "        P.append(p)\n",
    "    Rn=[]\n",
    "    for i in range(m):\n",
    "        for u in range(len(RrN[i])):\n",
    "            Rn.append(RrN[i][u])\n",
    "    return np.array(Rn), P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find which real users of R are in an account\n",
    "def UsersIn_a(a='account index'):\n",
    "    for value in SA.iloc[np.where((SA['are mixed in row of R_sa']) == a)].iloc[:,1]:\n",
    "        return value\n",
    "\n",
    "# To find where are the decomposed users of account a\n",
    "def DecomposedUsersOf_a(a):\n",
    "    t=0\n",
    "    for i in range(a+1):\n",
    "        t += int(A_B[i].sum())\n",
    "    return (int(t-A_B[i].sum()+1),t)\n",
    "\n",
    "def IdentifiedMapping(account_index='the account index of R_sa'):\n",
    "    '''\n",
    "    this function show the map of real users that were mixed in the given account to the identified users in Rn: the new reconstructed matrix'\n",
    "    Out put : [users or rows of R, algorithm Decomposed their shared account to these rows or Rn]\n",
    "    '''\n",
    "    ground_truth = UsersIn_a(account_index)\n",
    "    identified = [i-1 for i in range(DecomposedUsersOf_a(account_index)[0],DecomposedUsersOf_a(account_index)[1]+1)]\n",
    "    return identified, ground_truth\n",
    "# identified, ground_truth = IdentifiedMapping(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeRowSimilarity(identified, ground_truth):\n",
    "    n = len(identified)\n",
    "    num_agree = np.sum(identified == ground_truth)\n",
    "    similarity = max(num_agree/n,1-num_agree/n)\n",
    "#     similarity = num_agree/n\n",
    "    return np.round(similarity,4)\n",
    "\n",
    "def ComputeSimilarity(A_B='account membership matrix',Rn='Recunstructed ratings', R='real ratings'):\n",
    "    best_pairs = []\n",
    "    for account_index in range(A_B.shape[0]):\n",
    "        identified, ground_truth = IdentifiedMapping(account_index)\n",
    "        gt=ground_truth.copy()\n",
    "        if len(identified)<len(ground_truth):\n",
    "            for i in range(len(ground_truth)-len(identified)):\n",
    "                identified.append(identified[0])\n",
    "        for u in identified:\n",
    "            sim_u = []\n",
    "            for t in gt:\n",
    "                sim_u.append([u, t, ComputeRowSimilarity(Rn[u],R[t])])\n",
    "            s = []\n",
    "            best = []\n",
    "            best_pair_for_identified = []\n",
    "            for i in range(len(sim_u)):\n",
    "                s.append(sim_u[i][2])\n",
    "            best.append([np.argmax(s),max(s)])\n",
    "            best_pair_for_identified.append(sim_u[best[0][0]])\n",
    "            gt.remove(best_pair_for_identified[0][1])\n",
    "            best_pairs.append(best_pair_for_identified[0])\n",
    "            if len(gt)==0:\n",
    "                    break\n",
    "    return best_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rr = sps.coo_matrix(np.array(pd.read_csv('InputData/Rr.csv').loc[:,'0':'1679'],dtype='float'))\n",
    "def ComputeRMSE(R):\n",
    "    R = sps.coo_matrix(R)\n",
    "    R = pd.DataFrame({'CharacterID': R.row , 'MovieID': R.col , 'Rating': R.data})\n",
    "    reader = Reader()\n",
    "    data = Dataset.load_from_df(R,reader)\n",
    "    algo = BaselineOnly()\n",
    "#     algo = CoClustering()\n",
    "    # algo = SVD()\n",
    "#     algo = KNNBaseline()\n",
    "    output = cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=False)\n",
    "    return np.round(output['test_rmse'].mean(),4)\n",
    "\n",
    "def ComputeRMSE_vectors(prediction,target):\n",
    "    return np.round(np.sqrt(((prediction-target)**2).mean()),4)\n",
    "\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    return np.round(((np.dot(vector1,vector2))/(np.linalg.norm(vector1)*np.linalg.norm(vector2))),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserIdentificationMeasure(SA = 'ground truth mapping', A_B = 'account membership matrix'):\n",
    "    ''' SA :mapping of merging accounts',A_hat_B'account membership matrix '''\n",
    "    A_B = pd.DataFrame(A_B)\n",
    "    TP1, TN1, FP1, FN1 = 0,0,0,0\n",
    "    for i in range(SA.shape[0]):\n",
    "        if len(SA[\"rows of R\"][i]) == 1:   #اگه واقعا تک کاربره بود\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 1 :   # الگوریتم تک کاربره شناساییش کرده بود\n",
    "                TP1 +=1\n",
    "            else:   # الگوریتم تک کاربره شناساییش نکرده بود\n",
    "                FN1 +=1\n",
    "        else:                            #اگه واقعا تک کاربره نبود\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 1 :   # الگوریتم تک کاربره شناساییش کرده بود\n",
    "                FP1 +=1\n",
    "            else:   # الگوریتم تک کاربره شناساییش نکرده بود\n",
    "                TN1 +=1   \n",
    "    precision1 = np.round(TP1 / (TP1 + FP1),2)\n",
    "    accuracy1 = np.round((TP1 + TN1) / (TP1 + TN1 + FP1 + FN1),2)\n",
    "\n",
    "\n",
    "    TP2, TN2, FP2, FN2 = 0,0,0,0\n",
    "    for i in range(SA.shape[0]):\n",
    "        if len(SA[\"rows of R\"][i]) == 2:                      #اگه واقعا دو کاربره بود\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 2 :   # الگوریتم دو کاربره شناساییش کرده بود\n",
    "                TP2 +=1\n",
    "            else:                                           # الگوریتم دو کاربره شناساییش نکرده بود\n",
    "                FN2 +=1\n",
    "        else:                                               #اگه واقعا دو کاربره نبود\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 2 :   # الگوریتم دو کاربره شناساییش کرده بود\n",
    "                FP2 +=1\n",
    "            else:                                           # الگوریتم دو کاربره شناساییش نکرده بود\n",
    "                TN2 +=1   \n",
    "    precision2 = np.round(TP2 / (TP2 + FP2),2)\n",
    "    accuracy2 = np.round((TP2 + TN2) / (TP2 + TN2 + FP2 + FN2),2)\n",
    "\n",
    "\n",
    "    TP3, TN3, FP3, FN3 = 0,0,0,0\n",
    "    for i in range(SA.shape[0]):\n",
    "        if len(SA[\"rows of R\"][i]) == 3:                      #اگه واقعا 3 کاربره بود\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 3 :   # الگوریتم 3 کاربره شناساییش کرده بود\n",
    "                TP3 +=1\n",
    "            else:                                           # الگوریتم 3 کاربره شناساییش نکرده بود\n",
    "                FN3 +=1\n",
    "        else:                                               #اگه واقعا 3 کاربره نبود\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 3 :   # الگوریتم 3 کاربره شناساییش کرده بود\n",
    "                FP3 +=1\n",
    "            else:                                           # الگوریتم 3 کاربره شناساییش نکرده بود\n",
    "                TN3 +=1   \n",
    "    try:\n",
    "        precision3 = np.round(TP3 / (TP3 + FP3),2)\n",
    "    except ZeroDivisionError:\n",
    "        precision3 = 0\n",
    "    accuracy3 = np.round((TP3 + TN3) / (TP3 + TN3 + FP3 + FN3),2)\n",
    "\n",
    "\n",
    "    TP4, TN4, FP4, FN4 = 0,0,0,0\n",
    "    for i in range(SA.shape[0]):\n",
    "        if len(SA[\"rows of R\"][i]) == 4:                      #اگه واقعا 4 کاربره بود\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 4 :   # الگوریتم 4 کاربره شناساییش کرده بود\n",
    "                TP4 +=1\n",
    "            else:                                           # الگوریتم 4 کاربره شناساییش نکرده بود\n",
    "                FN4 +=1\n",
    "        else:                                               #اگه واقعا 4 کاربره نبود\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 4 :   # الگوریتم 4 کاربره شناساییش کرده بود\n",
    "                FP4 +=1\n",
    "            else:                                           # الگوریتم 4 کاربره شناساییش نکرده بود\n",
    "                TN4 +=1   \n",
    "    try:\n",
    "        precision4 = np.round(TP4 / (TP4 + FP4),2)\n",
    "    except ZeroDivisionError:\n",
    "        precision4 = 0\n",
    "    accuracy4 = np.round((TP4 + TN4) / (TP4 + TN4 + FP4 + FN4),2)\n",
    "    \n",
    "    data = [[precision1, precision2, precision3, precision4,],[accuracy1,accuracy2,accuracy3, accuracy4]]\n",
    "    col = ['singleUser Accounts', 'TwoUser  Accounts', 'ThreeUser  Accounts', 'FourUser  Accounts']\n",
    "    row = ['precision', 'accuracy']\n",
    "    table = pd.DataFrame(data, index=row, columns=col)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Confusion(SA = 'ground truth mapping', A_B = 'account membership matrix'):\n",
    "    ''' SA :mapping of merging accounts',A_hat_B'account membership matrix '''\n",
    "    A_B = pd.DataFrame(A_B)\n",
    "    T1I1, T1I2, T1I3, T1I4= 0,0,0,0\n",
    "    T2I1, T2I2, T2I3, T2I4= 0,0,0,0\n",
    "    T3I1, T3I2, T3I3, T3I4= 0,0,0,0\n",
    "    T4I1, T4I2, T4I3, T4I4= 0,0,0,0\n",
    "\n",
    "    for i in range(SA.shape[0]):\n",
    "        if len(SA[\"rows of R\"][i]) == 1:\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 1 :\n",
    "                T1I1 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 2 :\n",
    "                T1I2 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 3 :\n",
    "                T1I3 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 4 :\n",
    "                T1I4 +=1\n",
    "        elif len(SA[\"rows of R\"][i]) == 2:\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 1 :\n",
    "                T2I1 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 2 :\n",
    "                T2I2 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 3 :\n",
    "                T2I3 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 4 :\n",
    "                T2I4 +=1\n",
    "        elif len(SA[\"rows of R\"][i]) == 3:\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 1 :\n",
    "                T3I1 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 2 :\n",
    "                T3I2 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 3 :\n",
    "                T3I3 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 4 :\n",
    "                T3I4 +=1\n",
    "        elif len(SA[\"rows of R\"][i]) == 4:\n",
    "            if A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 1 :\n",
    "                T4I1 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 2 :\n",
    "                T4I2 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 3 :\n",
    "                T4I3 +=1\n",
    "            elif A_B.iloc[SA['are mixed in row of R_sa'][i]].sum() == 4 :\n",
    "                T4I4 +=1\n",
    "\n",
    "    data = [[T1I1, T1I2, T1I3, T1I4],\n",
    "            [T2I1, T2I2, T2I3, T2I4],\n",
    "            [T3I1, T3I2, T3I3, T3I4],\n",
    "            [T4I1, T4I2, T4I3, T4I4]]\n",
    "\n",
    "    col = ['singleUser', 'TwoUser', 'ThreeUser', 'FourUser']\n",
    "    row = ['singleUser', 'TwoUser', 'ThreeUser', 'FourUser']\n",
    "    table = pd.DataFrame(data, index=row, columns=col)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Lens 100k Input Data & shared version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "m_g_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url', 'unknown', 'Action', 'Adventure', 'Animation'\n",
    "           , 'Children', 'Comedy','Crime', 'Documentary', 'Drama', 'Fantasy'\n",
    "           , 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "\n",
    "data_set_path_users = \"InputData/ml-100k/u.user\"\n",
    "data_set_path_ratings = \"InputData/ml-100k/u.data\"\n",
    "data_set_path_movies = \"InputData/ml-100k/u.item\"\n",
    "users = pd.read_csv(data_set_path_users,sep='|',names = u_cols)\n",
    "ratings = pd.read_csv(data_set_path_ratings,sep='\\t', names = r_cols).drop('timestamp',axis=1)\n",
    "movies = pd.read_csv(data_set_path_movies, sep='|', names = m_cols, usecols=range(5))\n",
    "movies_genre_df = pd.read_csv(data_set_path_movies, sep='|', names = m_g_cols).drop(['title', 'release_date', 'video_release_date', 'imdb_url'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the unknown items(movie) from our data - when we have the features of the items we can wok on it\n",
    "# wherein our focosed feature is the genre of the movie so we find the movies with unknow genre and remove it from our dfs\n",
    "movie_ids_to_be_removed = list(movies_genre_df[movies_genre_df['unknown'] == 1]['movie_id'])\n",
    "for ids in movie_ids_to_be_removed:\n",
    "    ratings.drop((ratings[ratings['movie_id'] == ids]).index, inplace=True)\n",
    "    movies.drop((movies[movies['movie_id'] == ids]).index, inplace=True)\n",
    "    movies_genre_df.drop((movies_genre_df[movies_genre_df['movie_id'] == ids]).index, inplace=True)  \n",
    "# To Test run the code below\n",
    "# ratings.iloc[ratings[ratings['movie_id'] == ids].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulding Movie-Character Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G : Movie-Genre Matrix\n",
    "# W : Genre-Character Matrix\n",
    "# M : Movie-Character Matrix\n",
    "G = np.array(movies_genre_df.drop(['movie_id','unknown'],axis=1))\n",
    "\n",
    "W = np.array(pd.read_csv('InputData/W_clustered_normal.csv'))[0:18,1:5]\n",
    "weighting = 'Clustering'\n",
    "\n",
    "# W = np.array(pd.read_csv('InputData/W_accounts_clustered_normal.csv'))[0:18,1:5]\n",
    "# weighting = 'Accounts Clustered'\n",
    "\n",
    "\n",
    "# W = np.array(pd.read_csv('InputData/W4c.csv'))[0:18,1:5]\n",
    "# weighting = 'Wuhr'\n",
    "\n",
    "M = np.array(np.dot(G,W).T,dtype='float')\n",
    "# pd.DataFrame(M).to_csv('InputData/M_clustering.csv')\n",
    "# pd.DataFrame(M).to_csv('InputData/M_wuhr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input: Dataset Loading Account-Movie Ratings Matrix R_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_SAD4:    The Rating matrix of Shared Account Dataset with 4 user type mixture\n",
    "# R_SAD_NC:  The Rating matrix of Shared account with no collision assumption\n",
    "# GT_SAD4:   The Ground Truth Mapping of Shared Account Dataset with 4 user type mixture generaated\n",
    "# GT_SAD_NC: The Ground Truth Mapping of Shared Account with no collision assumption\n",
    "R = np.array(pd.read_csv('InputData/R.csv').loc[:,'1':'1682'],dtype='float')\n",
    "\n",
    "def R_SAD_2U_sum():\n",
    "    R_sa = np.array(pd.read_csv('InputData/R_SAD_2U.csv').loc[:,'0':'1679'],dtype='float')\n",
    "    SA = pd.read_csv(\"InputData/GT_SAD_2U.csv\")   # Ground truth mapping\n",
    "    SA['rows of R'] = SA['rows of R'].apply(lambda x: [int(i) for i in x.strip('[').strip(']').split(', ')])   # Splitting the 'rows of' column into lists of integers\n",
    "    dataset_name = 'R_SAD_2U_sum'\n",
    "    lA = 0.77\n",
    "    return R_sa, SA, lA, dataset_name\n",
    "\n",
    "\n",
    "def R_SAD_Extra():\n",
    "    R_sa = np.array(pd.read_csv('InputData/R_SAD_Extra.csv').loc[:,'0':'1679'],dtype='float')\n",
    "    SA = pd.read_csv(\"InputData/GT_SAD_Extra.csv\")   # Ground truth mapping\n",
    "    SA['rows of R'] = SA['rows of R'].apply(lambda x: [int(i) for i in x.strip('[').strip(']').split(', ')])   # Splitting the 'rows of' column into lists of integers\n",
    "    dataset_name = 'R_SAD_Extra'\n",
    "    lA = 0.77\n",
    "    return R_sa, SA, lA, dataset_name\n",
    "\n",
    "def R_SAD_NC():\n",
    "    R_sa = np.array(pd.read_csv('InputData/R_SAD_NC.csv').loc[:,'0':'1679'],dtype='float')\n",
    "    SA = pd.read_csv(\"InputData/GT_SAD_NC.csv\")   # Ground truth mapping\n",
    "    SA['rows of R'] = SA['rows of R'].apply(lambda x: [int(i) for i in x.strip('[').strip(']').split(', ')])   # Splitting the 'rows of' column into lists of integers\n",
    "    dataset_name = 'R_SAD_NC'\n",
    "    lA = 0.77\n",
    "    return R_sa, SA, lA, dataset_name\n",
    "\n",
    "\n",
    "def R_SAD4_WC():\n",
    "    R_sa = np.array(pd.read_csv('InputData/R_SAD4.csv').loc[:,'0':'1679'],dtype='float')\n",
    "    SA = pd.read_csv(\"InputData/GT_SAD4.csv\")   # Ground truth mapping\n",
    "    SA['rows of R'] = SA['rows of R'].apply(lambda x: [int(i) for i in x.strip('[').strip(']').split(', ')])   # Splitting the 'rows of' column into lists of integers\n",
    "    dataset_name = 'R_SAD4_WC'\n",
    "    lA = 0.735\n",
    "    return R_sa, SA, lA, dataset_name\n",
    "\n",
    "\n",
    "def R_SAD_4C_sum():\n",
    "    R_sa = np.array(pd.read_csv('InputData/R_SAD_4C_sum.csv').loc[:,'0':'1679'],dtype='float')\n",
    "    SA = pd.read_csv(\"InputData/GT_SAD_4C_sum.csv\")   # Ground truth mapping\n",
    "    SA['rows of R'] = SA['rows of R'].apply(lambda x: [int(i) for i in x.strip('[').strip(']').split(', ')])   # Splitting the 'rows of' column into lists of integers\n",
    "    dataset_name = 'R_SAD_4Clusters'\n",
    "    lA = 0.77\n",
    "    return R_sa, SA, lA, dataset_name\n",
    "\n",
    "def R_SAD_4C_mean():\n",
    "    R_sa = np.array(pd.read_csv('InputData/R_SAD_4C_mean.csv').loc[:,'0':'1679'],dtype='float')\n",
    "    SA = pd.read_csv(\"InputData/GT_SAD_4C_mean.csv\")   # Ground truth mapping\n",
    "    SA['rows of R'] = SA['rows of R'].apply(lambda x: [int(i) for i in x.strip('[').strip(']').split(', ')])   # Splitting the 'rows of' column into lists of integers\n",
    "    dataset_name = 'R_SAD_4Clusters'\n",
    "    lA = 0.77\n",
    "    return R_sa, SA, lA, dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Binary Nimfa solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Iter: 1 Obj value: 1509511.6047726958 satisfiability True evar 2.6182455270529204e-07\n",
      "Iter: 2 Obj value: 967578.7434591388 satisfiability True evar 0.3590122215264676\n",
      "Iter: 3 Obj value: 951663.361104551 satisfiability True evar 0.3695556172428235\n",
      "Iter: 4 Obj value: 951463.2477950538 satisfiability True evar 0.36968818545658877\n",
      "Iter: 5 Obj value: 951350.4508942239 satisfiability True evar 0.36976290954015345\n",
      "Iter: 6 Obj value: 951182.51852223 satisfiability True evar 0.3698741589850031\n",
      "Iter: 7 Obj value: 950924.9624418876 satisfiability True evar 0.3700447810670683\n",
      "Iter: 8 Obj value: 950529.988932095 satisfiability True evar 0.37030643748966885\n",
      "Iter: 9 Obj value: 949928.9777292459 satisfiability True evar 0.3707045868272356\n",
      "Iter: 10 Obj value: 949003.1136322854 satisfiability True evar 0.37131794008110874\n",
      "Iter: 11 Obj value: 947537.5052805906 satisfiability True evar 0.37228885541778367\n",
      "Iter: 12 Obj value: 945466.9656028415 satisfiability True evar 0.37366051703938663\n",
      "Iter: 13 Obj value: 942594.2221608482 satisfiability True evar 0.37556361117974\n",
      "Iter: 14 Obj value: 938294.0140057348 satisfiability True evar 0.37841235180261246\n",
      "Iter: 15 Obj value: 932509.5814262946 satisfiability True evar 0.3822443402726877\n",
      "Iter: 16 Obj value: 925799.1489793241 satisfiability True evar 0.38668977193998844\n",
      "Iter: 17 Obj value: 918896.7089368568 satisfiability True evar 0.39126240206314566\n",
      "Iter: 18 Obj value: 912307.8503679245 satisfiability True evar 0.3956272952000881\n",
      "Iter: 19 Obj value: 906294.4919354597 satisfiability True evar 0.3996109392072009\n",
      "Iter: 20 Obj value: 901033.6777733929 satisfiability True evar 0.4030960484094245\n",
      "Iter: 21 Obj value: 896719.4272286219 satisfiability True evar 0.40595409163450047\n",
      "Iter: 22 Obj value: 893583.2955711647 satisfiability True evar 0.4080316714466896\n",
      "Iter: 23 Obj value: 891859.0981782473 satisfiability True evar 0.40917389316663444\n",
      "Iter: 24 Obj value: 891732.1422313921 satisfiability True evar 0.40925799713325095\n",
      "Iter: 25 Obj value: 893299.0171516776 satisfiability False evar 0.4082199961632119\n",
      "Best objective value: 893299.0171516776\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from nimfa.models import *\n",
    "from nimfa.utils.linalg import dot, multiply, elop, div, power\n",
    "import sys\n",
    "\n",
    "class MyBmf(Bmf):\n",
    "    def __init__(self, V, rank=30, max_iter=30, min_residuals=1e-1, test_conv=None,\n",
    "                 lambda_w=1.1, lambda_h=1.1, verbose=True, **options):\n",
    "        self.verbose = verbose\n",
    "        Bmf.__init__(self, V, rank=rank, max_iter=max_iter, min_residuals=min_residuals,\n",
    "                     test_conv=test_conv, lambda_w=lambda_w, lambda_h=lambda_h, **options)\n",
    "\n",
    "    def factorize(self):\n",
    "        self._lambda_w = 1. / self.max_iter if self.max_iter else 1. / 10\n",
    "        self._lambda_h = self._lambda_w\n",
    "        for run in range(self.n_run):\n",
    "            self.W, self.H = self.seed.initialize(self.V, self.rank, self.options)\n",
    "            self.normalize()\n",
    "            p_obj = c_obj = sys.float_info.max\n",
    "            best_obj = c_obj if run == 0 else best_obj\n",
    "            iter = 0\n",
    "            if self.verbose:\n",
    "                print(\"Run:\", run+1)\n",
    "            while self.is_satisfied(p_obj, c_obj, iter):\n",
    "                p_obj = c_obj if not self.test_conv or iter % self.test_conv == 0 else p_obj\n",
    "                self.update()\n",
    "                self._adjustment()\n",
    "                iter += 1\n",
    "                c_obj = self.objective() if not self.test_conv or iter % self.test_conv == 0 else c_obj\n",
    "                if self.verbose:\n",
    "                    print(\"Iter:\", iter, \"Obj value:\", c_obj, \n",
    "                          'satisfiability',model.is_satisfied(p_obj, c_obj, iter), 'evar',model.evar())\n",
    "            # if multiple runs are performed, fitted factorization model with\n",
    "            # the lowest objective function value is retained\n",
    "            if c_obj <= best_obj or run == 0:\n",
    "                best_obj = c_obj\n",
    "                self.n_iter = iter\n",
    "                self.final_obj = c_obj\n",
    "                mffit = mf_fit.Mf_fit(copy.deepcopy(self))\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"Best objective value:\", best_obj)\n",
    "        mffit.fit.tracker = self.tracker\n",
    "        return mffit\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "m, n = R_sa.shape   # Number of users and movies\n",
    "k = M.shape[0]   # Number of features\n",
    "A = np.ones((m,k),dtype=float)\n",
    "A = np.ones((m,k),dtype=float)\n",
    "model = MyBmf(R_sa, seed=None, W=A, H = M, rank=k, max_iter=4500, lambda_w=1.9, lambda_h= 0.1, verbose=True)\n",
    "fit = model.factorize()\n",
    "A = fit.basis()\n",
    "NM = fit.coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_w=1.35/lA = 0.83/lambda_h= 0.1//max_iter=1000\n",
    "# lambda_w=1.40/lA = 0.845/max_iter=1000\n",
    "# lambda_w=1.45/lA = 0.85/max_iter=1000\n",
    "# lambda_w=1.50/lA = 0.848/max_iter=1000\n",
    "# lambda_w=1.55/lA = 0.86/max_iter=1000\n",
    "# lambda_w=1.60/lA = 0.89/max_iter=1000\n",
    "# lambda_w=1.65/lA = 0.89/max_iter=1000\n",
    "# lambda_w=1.70/lA = 0.9/max_iter=1000\n",
    "# lambda_w=1.75/lA = 0.915/max_iter=1000\n",
    "# lambda_w=1.80/lA = 0.923/max_iter=1000\n",
    "# lambda_w=1.85/lA = 0.92/max_iter=3500\n",
    "# lambda_w=1.85/lA = 0.972/max_iter=1000\n",
    "# lambda_w=1.9/lA = 0.97/max_iter=1000\n",
    "# lambda_w=1.9/max_iter=5000, lambda_w=1.9/lA = 0.93 / TwoUserTwoUser=75 **\n",
    "# max_iter=4500, lambda_w=1.9 /lA = 0.933/ TwoUserTwoUser=76 ***\n",
    "# lambda_w=1.9/max_iter=4000, lambda_w=1.9/lA = 0.923 / TwoUserTwoUser=76 ***\n",
    "# max_iter=3500, lambda_w=1.9 /lA = 0.929/ TwoUserTwoUser=76 ***\n",
    "# lambda_w=1.9/max_iter=3000, lambda_w=1.9/lA = 0.932 / TwoUserTwoUser=75 **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of accounts= 784\n",
      "Identified Profiles 943.0\n",
      "Profile1    151.0\n",
      "Profile2    182.0\n",
      "Profile3    403.0\n",
      "Profile4    207.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         585       45          1         1\n",
      "TwoUser             59       76          9         2\n",
      "ThreeUser            0        3          2         0\n",
      "FourUser             0        0          1         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.91               0.61                 0.15   \n",
       "accuracy                  0.86               0.85                 0.98   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                0.00  \n",
       "accuracy                 0.99  "
      ]
     },
     "execution_count": 1167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('number of accounts=', R_sa.shape[0])\n",
    "lA = 0.933\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of accounts= 784\n",
      "Identified Profiles 943.0\n",
      "Profile1    145.0\n",
      "Profile2    182.0\n",
      "Profile3    412.0\n",
      "Profile4    204.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         582       47          2         1\n",
      "TwoUser             59       79          6         2\n",
      "ThreeUser            0        3          2         0\n",
      "FourUser             0        1          0         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.91               0.61                 0.20   \n",
       "accuracy                  0.86               0.85                 0.99   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                0.00  \n",
       "accuracy                 0.99  "
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('number of accounts=', R_sa.shape[0])\n",
    "lA = 0.9425\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryNimfaSolver(R_sa, M, max_iter=1000, lambda_w=1.1, lambda_h=1.01):\n",
    "    import nimfa\n",
    "    m, n = R_sa.shape   # Number of users and movies\n",
    "    k = M.shape[0]   # Number of features\n",
    "    A = np.ones((m,k),dtype=float)\n",
    "#     A = np.ones((m,k),dtype=float)/2\n",
    "#     A = np.zeros((m,k),dtype=float)\n",
    "    \n",
    "    bmf = nimfa.Bmf(R_sa, seed=None, W=A, H = M, rank=k, max_iter= max_iter, lambda_w= lambda_w, lambda_h= lambda_h)\n",
    "    bmf_fit = bmf()\n",
    "    A = bmf_fit.basis()\n",
    "    MN = bmf_fit.coef()\n",
    "    return np.asarray(A), np.asarray(MN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using W with clustering shared ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD_4Clusters\n"
     ]
    }
   ],
   "source": [
    "R_sa, SA, lA, dataset_name = R_SAD_4C_sum()\n",
    "print('dataset_name:',dataset_name)\n",
    "# A = GD_solver(R_sa, M)\n",
    "A, MN = BinaryNimfaSolver(R_sa, M, max_iter=8000, lambda_w=1.1, lambda_h=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of accounts= 784\n",
      "Identified Profiles 963.0\n",
      "Profile1    177.0\n",
      "Profile2    159.0\n",
      "Profile3    429.0\n",
      "Profile4    198.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         536       89          7         0\n",
      "TwoUser             87       49         10         0\n",
      "ThreeUser            0        4          1         0\n",
      "FourUser             0        1          0         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.86               0.34                 0.06   \n",
       "accuracy                  0.77               0.76                 0.97   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 1012,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('number of accounts=', R_sa.shape[0])\n",
    "lA = 0.75\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                    v1.1.15                                    \n",
      "===============================================================================\n",
      "(CVXPY) May 13 06:35:13 PM: Your problem has 3136 variables, 0 constraints, and 6720 parameters.\n",
      "(CVXPY) May 13 06:35:13 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) May 13 06:35:13 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 13 06:35:13 PM: Compiling problem (target solver=ECOS).\n",
      "(CVXPY) May 13 06:35:13 PM: Reduction chain: Dcp2Cone -> CvxAttr2Constr -> ConeMatrixStuffing -> ECOS\n",
      "(CVXPY) May 13 06:35:13 PM: Applying reduction Dcp2Cone\n",
      "(CVXPY) May 13 06:35:13 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) May 13 06:35:13 PM: Applying reduction ConeMatrixStuffing\n",
      "(CVXPY) May 13 06:37:08 PM: Applying reduction ECOS\n",
      "(CVXPY) May 13 06:37:09 PM: Finished problem compilation (took 1.162e+02 seconds).\n",
      "(CVXPY) May 13 06:37:09 PM: (Subsequent compilations of this problem, using the same arguments, should take less time.)\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 13 06:37:09 PM: Invoking solver ECOS  to obtain a solution.\n",
      "\n",
      "ECOS 2.0.7 - (C) embotech GmbH, Zurich Switzerland, 2012-15. Web: www.embotech.com/ECOS\n",
      "\n",
      "It     pcost       dcost      gap   pres   dres    k/t    mu     step   sigma     IR    |   BT\n",
      " 0  +0.000e+00  -0.000e+00  +2e+04  1e+00  3e-03  1e+00  8e+00    ---    ---    1  2  - |  -  - \n",
      " 1  +7.188e+01  +7.189e+01  +2e+03  5e-02  3e-04  1e-01  8e-01  0.8967  1e-04   3  3  3 |  0  0\n",
      " 2  -1.439e+01  -1.414e+01  +9e+02  1e-02  2e-04  3e-01  3e-01  0.9043  3e-01   5  5  5 |  0  0\n",
      " 3  +4.650e+02  +4.651e+02  +3e+02  4e-03  4e-05  1e-01  9e-02  0.7150  7e-02   5  6  6 |  0  0\n",
      " 4  +5.175e+02  +5.176e+02  +1e+02  1e-03  1e-05  5e-02  3e-02  0.9251  3e-01   2  2  2 |  0  0\n",
      " 5  +5.943e+02  +5.943e+02  +2e+01  3e-04  3e-06  1e-02  7e-03  0.8331  6e-02   3  3  3 |  0  0\n",
      " 6  +6.028e+02  +6.028e+02  +7e+00  6e-05  8e-07  3e-03  2e-03  0.8493  2e-01   2  2  2 |  0  0\n",
      " 7  +6.043e+02  +6.043e+02  +3e+00  2e-05  4e-07  1e-03  9e-04  0.6851  1e-01   1  1  2 |  0  0\n",
      " 8  +6.049e+02  +6.049e+02  +2e+00  2e-05  3e-07  1e-03  6e-04  0.5549  5e-01   2  2  2 |  0  0\n",
      " 9  +6.055e+02  +6.055e+02  +4e-01  2e-06  5e-08  2e-04  1e-04  0.8833  7e-02   1  2  2 |  0  0\n",
      "10  +6.056e+02  +6.056e+02  +6e-02  4e-07  7e-09  3e-05  2e-05  0.8963  6e-02   1  2  1 |  0  0\n",
      "11  +6.056e+02  +6.056e+02  +2e-02  1e-07  2e-09  8e-06  6e-06  0.8143  2e-01   1  1  1 |  0  0\n",
      "12  +6.056e+02  +6.056e+02  +4e-03  3e-08  5e-10  2e-06  1e-06  0.8734  1e-01   2  1  1 |  0  0\n",
      "13  +6.056e+02  +6.056e+02  +1e-03  7e-09  1e-10  5e-07  3e-07  0.8234  8e-02   1  1  1 |  0  0\n",
      "14  +6.056e+02  +6.056e+02  +5e-05  4e-10  6e-12  2e-08  1e-08  0.9631  9e-03   1  1  1 |  0  0\n",
      "15  +6.056e+02  +6.056e+02  +2e-06  5e-11  6e-13  1e-09  7e-10  0.9521  2e-03   2  1  1 |  0  0\n",
      "\n",
      "OPTIMAL (within feastol=5.1e-11, reltol=3.8e-09, abstol=2.3e-06).\n",
      "Runtime: 16.274742 seconds.\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) May 13 06:37:25 PM: Problem status: optimal\n",
      "(CVXPY) May 13 06:37:25 PM: Optimal value: 6.056e+02\n",
      "(CVXPY) May 13 06:37:25 PM: Compilation took 1.162e+02 seconds\n",
      "(CVXPY) May 13 06:37:25 PM: Solver (including time spent in interface) took 1.639e+01 seconds\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "m, n = R_sa.shape   # Number of accounts and movies\n",
    "O = np.array(R_sa != 0,dtype='float')   # Producing Observation matrix \n",
    "k = M.shape[0]   # Number of features\n",
    "R = R_sa.astype(np.float32)  # rating matrix R\n",
    "V = M.astype(np.float32)  # Known item feature matrix V\n",
    "V_constant = cp.Parameter((k, n), value=V)\n",
    "\n",
    "U = cp.Variable((m, k), nonneg=True)  # Ensures U is non-negative\n",
    "# objective = cp.Minimize(cp.norm(R - cp.multiply(O,(U @ V_constant)), 'fro') + 0.1 * cp.norm(U, 1))\n",
    "objective = cp.Minimize(cp.norm(R - cp.multiply(O,(U @ V_constant)), 'fro'))\n",
    "\n",
    "problem = cp.Problem(objective)\n",
    "# result = problem.solve(solver=cp.SCS, verbose=True)\n",
    "# result = problem.solve(solver=cp.OSQP, max_iter=10000, verbose=True)\n",
    "result = problem.solve(solver='ECOS', abstol=1e-6, verbose=True)\n",
    "\n",
    "A = U.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of accounts= 784\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-625-292fe8cdd497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'number of accounts='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR_sa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.38\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mA_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproject_onto_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Identified Profiles'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA_B\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# frame working for ilustraticon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-6ba8623e0cc3>\u001b[0m in \u001b[0;36mproject_onto_face\u001b[1;34m(A, l)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mproject_onto_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'array_like_matrix'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "print('number of accounts=', R_sa.shape[0])\n",
    "lA = 0.38\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___Demixing ratings_____________________\n",
      "942 are decomsosed from 784 accounts.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 942 is out of bounds for axis 0 with size 784",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-617-85169e41eeb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mRn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'are decomsosed from'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mR_sa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'accounts.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mbest_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mComputeSimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_B\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mMeanSimilarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean Similarity of each reconstructed user s rating:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMeanSimilarity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-382b94bfb1e8>\u001b[0m in \u001b[0;36mComputeSimilarity\u001b[1;34m(A_B, Rn, R)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0msim_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0msim_u\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComputeRowSimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 942 is out of bounds for axis 0 with size 784"
     ]
    }
   ],
   "source": [
    "print('___Demixing ratings_____________________')\n",
    "Rn = Demix(R_sa, A, A_B, MN)\n",
    "Rn = Rn.astype(int)\n",
    "print(Rn.shape[0], 'are decomsosed from',R_sa.shape[0] ,'accounts.')\n",
    "best_pairs = ComputeSimilarity(A_B, Rn, R)\n",
    "MeanSimilarity = np.round(np.array(best_pairs)[:,2].mean(),4)\n",
    "print('Mean Similarity of each reconstructed user s rating:', MeanSimilarity)\n",
    "\n",
    "print(np.count_nonzero(Rn),' ratings has been identified from',np.count_nonzero(R_sa),'ratings in shared account rating matrix')\n",
    "print('Applying recommender on entire ratings: Baseline')\n",
    "print('RMSE on shared accounts ratings',dataset_name,':', ComputeRMSE(R_sa))    \n",
    "print('RMSE on reconstructed ratings',':', ComputeRMSE(Rn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified Profiles 1006.0\n",
      "Profile1    184.0\n",
      "Profile2    206.0\n",
      "Profile3    395.0\n",
      "Profile4    221.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         563       66          2         1\n",
      "TwoUser             44       69         29         4\n",
      "ThreeUser            0        2          3         0\n",
      "FourUser             0        0          1         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.93               0.50                 0.09   \n",
       "accuracy                  0.86               0.82                 0.96   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                0.00  \n",
       "accuracy                 0.99  "
      ]
     },
     "execution_count": 1361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=10000, lambda_w=1.6, lambda_h=1.01)\n",
    "lA = 0.85\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified Profiles 943.0\n",
      "Profile1    218.0\n",
      "Profile2    177.0\n",
      "Profile3    295.0\n",
      "Profile4    253.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         567       63          2         0\n",
      "TwoUser             73       61         11         1\n",
      "ThreeUser            1        3          1         0\n",
      "FourUser             0        1          0         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.88               0.48                 0.07   \n",
       "accuracy                  0.82               0.81                 0.98   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lA = 0.815\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___Demixing ratings_____________________\n",
      "943 are decomsosed from 784 accounts.\n",
      "Mean Similarity of each reconstructed user s rating: 0.9593\n",
      "99773  ratings has been identified from 95126 ratings in shared account rating matrix\n",
      "Applying recommender on entire ratings: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE on shared accounts ratings R_SAD_4Clusters : 1.2517\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE on reconstructed ratings : 1.2302\n",
      "Confusion matrix             singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         511      118          3         0\n",
      "TwoUser            114       29          3         0\n",
      "ThreeUser            5        0          0         0\n",
      "FourUser             1        0          0         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.81                0.2                 0.00   \n",
       "accuracy                  0.69                0.7                 0.99   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('___Demixing ratings_____________________')\n",
    "Rn = Demix(R_sa, A, A_B, MN)\n",
    "Rn = Rn.astype(int)\n",
    "print(Rn.shape[0], 'are decomsosed from',R_sa.shape[0] ,'accounts.')\n",
    "best_pairs = ComputeSimilarity(A_B, Rn, R)\n",
    "MeanSimilarity = np.round(np.array(best_pairs)[:,2].mean(),4)\n",
    "print('Mean Similarity of each reconstructed user s rating:', MeanSimilarity)\n",
    "\n",
    "print(np.count_nonzero(Rn),' ratings has been identified from',np.count_nonzero(R_sa),'ratings in shared account rating matrix')\n",
    "print('Applying recommender on entire ratings: Baseline')\n",
    "print('RMSE on shared accounts ratings',dataset_name,':', ComputeRMSE(R_sa))    \n",
    "print('RMSE on reconstructed ratings',':', ComputeRMSE(Rn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD_4Clusters\n"
     ]
    }
   ],
   "source": [
    "# M clustering\n",
    "R_sa, SA, lA, dataset_name = R_SAD_4Clusters()\n",
    "print('dataset_name:',dataset_name)\n",
    "A , MN = BinaryNimfaSolver(R_sa, M, max_iter=5000, lambda_w=2, lambda_h=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified Profiles 931.0\n",
      "Profile1    143.0\n",
      "Profile2    181.0\n",
      "Profile3    412.0\n",
      "Profile4    195.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         581       50          0         1\n",
      "TwoUser             67       70          8         1\n",
      "ThreeUser            2        2          1         0\n",
      "FourUser             0        1          0         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.89               0.57                 0.11   \n",
       "accuracy                  0.85               0.84                 0.98   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 1049,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lA = 0.94\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "\n",
    "print( Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuned parameterr\n",
    "A , MN = BinaryNimfaSolver(R_sa, M, max_iter=6000, lambda_w=2, lambda_h=1.1), lA = 0.942\n",
    "\n",
    "(max_iter=3500, lambda_w=1.8 , lambda_h=1.01) =====> IdentifidThreeUser = 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1882,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD_NC\n",
      "Identified Profiles 842.0\n",
      "Profile1    155.0\n",
      "Profile2    128.0\n",
      "Profile3    399.0\n",
      "Profile4    160.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         591       37          2         0\n",
      "TwoUser            132       12          3         0\n",
      "ThreeUser            5        0          0         0\n",
      "FourUser             1        0          0         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.81               0.24                 0.00   \n",
       "accuracy                  0.77               0.78                 0.99   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 1882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M clustering\n",
    "R_sa, SA, lA, dataset_name = R_SAD_NC()\n",
    "print('dataset_name:',dataset_name)\n",
    "A , MN = BinaryNimfaSolver(R_sa, M, max_iter=1000, lambda_w=1.1, lambda_h=1.01)\n",
    "lA = 0.9\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print( Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___Demixing ratings_____________________\n",
      "948 are decomsosed from 784 accounts.\n",
      "Mean Similarity of each reconstructed user s rating: 0.9574\n",
      "109115  ratings has been identified from 95126 ratings in shared account rating matrix\n",
      "Applying recommender on entire ratings: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE on shared accounts ratings R_SAD_4Clusters : 1.2515\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE on reconstructed ratings : 1.1172\n"
     ]
    }
   ],
   "source": [
    "print('___Demixing ratings_____________________')\n",
    "Rn = Demix(R_sa, A, A_B, MN)\n",
    "Rn = Rn.astype(int)\n",
    "print(Rn.shape[0], 'are decomsosed from',R_sa.shape[0] ,'accounts.')\n",
    "best_pairs = ComputeSimilarity(A_B, Rn, R)\n",
    "MeanSimilarity = np.round(np.array(best_pairs)[:,2].mean(),4)\n",
    "print('Mean Similarity of each reconstructed user s rating:', MeanSimilarity)\n",
    "\n",
    "print(np.count_nonzero(Rn),' ratings has been identified from',np.count_nonzero(R_sa),'ratings in shared account rating matrix')\n",
    "print('Applying recommender on entire ratings: Baseline')\n",
    "print('RMSE on shared accounts ratings',dataset_name,':', ComputeRMSE(R_sa))    \n",
    "print('RMSE on reconstructed ratings',':', ComputeRMSE(Rn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1866,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD_4Clusters\n",
      "Identified Profiles 945.0\n",
      "Profile1    146.0\n",
      "Profile2    182.0\n",
      "Profile3    413.0\n",
      "Profile4    204.0\n",
      "dtype: float64\n",
      "___Demixing ratings_____________________\n",
      "945 are decomsosed from 784 accounts.\n",
      "Mean Similarity of each reconstructed user s rating: 0.956\n",
      "109846  ratings has been identified from 95126 ratings in shared account rating matrix\n",
      "Applying recommender on entire ratings: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE on shared accounts ratings R_SAD_4Clusters : 1.2526\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE on reconstructed ratings : 1.1178\n",
      "Confusion matrix             singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         581       48          2         1\n",
      "TwoUser             58       80          6         2\n",
      "ThreeUser            0        3          2         0\n",
      "FourUser             0        1          0         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.91               0.61                 0.20   \n",
       "accuracy                  0.86               0.85                 0.99   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                0.00  \n",
       "accuracy                 0.99  "
      ]
     },
     "execution_count": 1866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M clustering\n",
    "R_sa, SA, lA, dataset_name = R_SAD_4C_sum()\n",
    "print('dataset_name:',dataset_name)\n",
    "A , MN = BinaryNimfaSolver(R_sa, M, max_iter=6000, lambda_w=2, lambda_h=1.1)\n",
    "lA = 0.942\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "\n",
    "print('___Demixing ratings_____________________')\n",
    "Rn = Demix(R_sa, A, A_B, MN)\n",
    "Rn = Rn.astype(int)\n",
    "print(Rn.shape[0], 'are decomsosed from',R_sa.shape[0] ,'accounts.')\n",
    "best_pairs = ComputeSimilarity(A_B, Rn, R)\n",
    "MeanSimilarity = np.round(np.array(best_pairs)[:,2].mean(),4)\n",
    "print('Mean Similarity of each reconstructed user s rating:', MeanSimilarity)\n",
    "\n",
    "print(np.count_nonzero(Rn),' ratings has been identified from',np.count_nonzero(R_sa),'ratings in shared account rating matrix')\n",
    "print('Applying recommender on entire ratings: Baseline')\n",
    "print('RMSE on shared accounts ratings',dataset_name,':', ComputeRMSE(R_sa))    \n",
    "print('RMSE on reconstructed ratings',':', ComputeRMSE(Rn))\n",
    "print('Confusion matrix', Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904\n",
      "Identified Profiles 942.0\n",
      "Profile1    164.0\n",
      "Profile2    195.0\n",
      "Profile3    397.0\n",
      "Profile4    186.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         586       45          1         0\n",
      "TwoUser             63       63         20         0\n",
      "ThreeUser            1        2          2         0\n",
      "FourUser             0        0          1         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.90               0.57                 0.08   \n",
       "accuracy                  0.86               0.83                 0.97   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=10000, lambda_w=1.8, lambda_h=1,\n",
    "lA = 0.904\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827\n",
      "Identified Profiles 943.0\n",
      "Profile1    201.0\n",
      "Profile2    169.0\n",
      "Profile3    408.0\n",
      "Profile4    165.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         568       58          6         0\n",
      "TwoUser             76       60         10         0\n",
      "ThreeUser            0        3          2         0\n",
      "FourUser             0        0          1         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.88               0.50                 0.11   \n",
       "accuracy                  0.82               0.81                 0.97   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=1000, lambda_w=1.3, lambda_h=1,\n",
    "lA = 0.827\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.901\n",
      "Identified Profiles 945.0\n",
      "Profile1    159.0\n",
      "Profile2    189.0\n",
      "Profile3    377.0\n",
      "Profile4    220.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         580       50          1         1\n",
      "TwoUser             63       70         11         2\n",
      "ThreeUser            0        4          1         0\n",
      "FourUser             0        0          1         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.90               0.56                 0.07   \n",
       "accuracy                  0.85               0.83                 0.98   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                0.00  \n",
       "accuracy                 0.99  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=1000, lambda_w=1.7, lambda_h=1,\n",
    "lA = 0.901\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853\n",
      "Identified Profiles 944.0\n",
      "Profile1    180.0\n",
      "Profile2    190.0\n",
      "Profile3    372.0\n",
      "Profile4    202.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         580       50          2         0\n",
      "TwoUser             65       64         17         0\n",
      "ThreeUser            0        4          1         0\n",
      "FourUser             0        0          1         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.90               0.54                 0.05   \n",
       "accuracy                  0.85               0.83                 0.97   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=500, lambda_w=1.5, lambda_h=1\n",
    "# max_iter=1000, lambda_w=1.5, lambda_h=1, lA = 0.847\n",
    "lA = 0.853\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n",
      "Identified Profiles 944.0\n",
      "Profile1    197.0\n",
      "Profile2    154.0\n",
      "Profile3    418.0\n",
      "Profile4    175.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         558       71          3         0\n",
      "TwoUser             83       51         12         0\n",
      "ThreeUser            0        4          1         0\n",
      "FourUser             0        0          1         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.87               0.40                 0.06   \n",
       "accuracy                  0.80               0.78                 0.97   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=100, lambda_w=1.1, lambda_h=1\n",
    "lA = 0.79\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793\n",
      "Identified Profiles 944.0\n",
      "Profile1    194.0\n",
      "Profile2    145.0\n",
      "Profile3    421.0\n",
      "Profile4    184.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         551       77          4         0\n",
      "TwoUser             90       45         11         0\n",
      "ThreeUser            0        4          1         0\n",
      "FourUser             0        0          1         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.86               0.36                 0.06   \n",
       "accuracy                  0.78               0.77                 0.97   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=1000, lambda_w=1.1, lambda_h=1\n",
    "lA = 0.793\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748\n",
      "Identified Profiles 943.0\n",
      "Profile1    174.0\n",
      "Profile2    149.0\n",
      "Profile3    425.0\n",
      "Profile4    195.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         551       76          5         0\n",
      "TwoUser             88       50          8         0\n",
      "ThreeUser            1        2          2         0\n",
      "FourUser             0        1          0         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.86               0.39                 0.13   \n",
       "accuracy                  0.78               0.78                 0.98   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=1000, lambda_w=1.01, lambda_h=1\n",
    "lA = 0.748\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748\n",
      "Identified Profiles 943.0\n",
      "Profile1    174.0\n",
      "Profile2    149.0\n",
      "Profile3    425.0\n",
      "Profile4    195.0\n",
      "dtype: float64\n",
      "            singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         551       76          5         0\n",
      "TwoUser             88       50          8         0\n",
      "ThreeUser            1        2          2         0\n",
      "FourUser             0        1          0         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision                 0.86               0.39                 0.13   \n",
       "accuracy                  0.78               0.78                 0.98   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision                 0.0  \n",
       "accuracy                  1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=1000, lambda_w=1.01, lambda_h=1.001\n",
    "lA = 0.748\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD_4Clusters\n",
      "Shared account rating matrix factorized.\n",
      "Binarizing account feature matrix by parameter lA= 0.735\n",
      "Identified Profiles 944.0\n",
      "Profile1    207.0\n",
      "Profile2    172.0\n",
      "Profile3    426.0\n",
      "Profile4    139.0\n",
      "dtype: float64\n",
      "___Decomposing ratings_____________________\n",
      "944 are decomsosed from 784 accounts.\n",
      "Mean Similarity of each reconstructed user s rating: 0.9528\n",
      "125685  ratings has been identified from 95126 ratings in shared account rating matrix\n",
      "Applying recommender on entire ratings: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE on shared accounts ratings R_SAD_4Clusters : 1.2512\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE on reconstructed ratings : 0.9874\n",
      "Confusion matrix             singleUser  TwoUser  ThreeUser  FourUser\n",
      "singleUser         547       79          6         0\n",
      "TwoUser             89       51          6         0\n",
      "ThreeUser            1        3          1         0\n",
      "FourUser             0        1          0         0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser Accounts</th>\n",
       "      <th>TwoUser  Accounts</th>\n",
       "      <th>ThreeUser  Accounts</th>\n",
       "      <th>FourUser  Accounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.8587</td>\n",
       "      <td>0.3806</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.7768</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.9796</td>\n",
       "      <td>0.9987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           singleUser Accounts  TwoUser  Accounts  ThreeUser  Accounts  \\\n",
       "precision               0.8587             0.3806               0.0769   \n",
       "accuracy                0.7768             0.7730               0.9796   \n",
       "\n",
       "           FourUser  Accounts  \n",
       "precision              0.0000  \n",
       "accuracy               0.9987  "
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_sa, SA, lA, dataset_name = R_SAD_4Clusters()\n",
    "print('dataset_name:',dataset_name)\n",
    "A , MN = BinaryNimfaSolver(R_sa, M, max_iter=1000, lambda_w=1.01, lambda_h=1.001)\n",
    "print('Shared account rating matrix factorized.')\n",
    "lA = 0.735\n",
    "print('Binarizing account feature matrix by parameter lA=',lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "\n",
    "print('___Decomposing ratings_____________________')\n",
    "Rn = Decompose(R_sa, A, A_B)\n",
    "print(Rn.shape[0], 'are decomsosed from',R_sa.shape[0] ,'accounts.')\n",
    "best_pairs = ComputeSimilarity(A_B, Rn, R)\n",
    "MeanSimilarity = np.round(np.array(best_pairs)[:,2].mean(),4)\n",
    "print('Mean Similarity of each reconstructed user s rating:', MeanSimilarity)\n",
    "\n",
    "print(np.count_nonzero(Rn),' ratings has been identified from',np.count_nonzero(R_sa),'ratings in shared account rating matrix')\n",
    "print('Applying recommender on entire ratings: Baseline')\n",
    "print('RMSE on shared accounts ratings',dataset_name,':', ComputeRMSE(R_sa))    \n",
    "print('RMSE on reconstructed ratings',':', ComputeRMSE(Rn))\n",
    "print('Confusion matrix', Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD_4Clusters\n",
      "0.735\n",
      "Identified Profiles 944.0\n",
      "Profile1    207.0\n",
      "Profile2    172.0\n",
      "Profile3    426.0\n",
      "Profile4    139.0\n",
      "dtype: float64\n",
      "_____________________________________\n",
      "demixed ratings 944\n",
      "Applying recommender: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE R_SAD_4Clusters : 1.2512\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE Reconstructed : 1.2414\n",
      "Similarity: 0.9603\n",
      "UserIdentification (0.8587, 0.7768, 0.3806, 0.773, 0.0769, 0.9796, 0, 0.9987)\n",
      "identified ratings 99495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser</th>\n",
       "      <th>TwoUser</th>\n",
       "      <th>ThreeUser</th>\n",
       "      <th>FourUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>singleUser</th>\n",
       "      <td>547</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoUser</th>\n",
       "      <td>89</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThreeUser</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FourUser</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            singleUser  TwoUser  ThreeUser  FourUser\n",
       "singleUser         547       79          6         0\n",
       "TwoUser             89       51          6         0\n",
       "ThreeUser            1        3          1         0\n",
       "FourUser             0        1          0         0"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_sa, SA, lA, dataset_name = R_SAD_4Clusters()\n",
    "print('dataset_name:',dataset_name)\n",
    "A , MN = BinaryNimfaSolver(R_sa, M, max_iter=1000, lambda_w=1.01, lambda_h=1.001)\n",
    "print('Shared account rating matrix factorized.')\n",
    "lA = 0.735\n",
    "print('Binarizing account feature matrix by parameter lA=',lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "\n",
    "print('___Demixing ratings_____________________')\n",
    "Rn = Demix(R_sa, A, A_B, MN)\n",
    "Rn = Rn.astype(int)\n",
    "print(Rn.shape[0], 'are decomsosed from',R_sa.shape[0] ,'accounts.')\n",
    "best_pairs = ComputeSimilarity(A_B, Rn, R)\n",
    "MeanSimilarity = np.round(np.array(best_pairs)[:,2].mean(),4)\n",
    "print('Mean Similarity of each reconstructed user s rating:', MeanSimilarity)\n",
    "\n",
    "print(np.count_nonzero(Rn),' ratings has been identified from',np.count_nonzero(R_sa),'ratings in shared account rating matrix')\n",
    "print('Applying recommender on entire ratings: Baseline')\n",
    "print('RMSE on shared accounts ratings',dataset_name,':', ComputeRMSE(R_sa))    \n",
    "print('RMSE on reconstructed ratings',':', ComputeRMSE(Rn))\n",
    "print('Confusion matrix', Confusion(SA,A_B))\n",
    "UserIdentificationMeasure(SA, A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD_4Clusters\n"
     ]
    }
   ],
   "source": [
    "R_sa, SA, lA, dataset_name = R_SAD_4Clusters()\n",
    "print('dataset_name:',dataset_name)\n",
    "A , MN = BinaryNimfaSolver(R_sa, M, max_iter=5000, lambda_w=1.001, lambda_h=1.001)\n",
    "# A = ANNsolver(R_sa,M, n_iterations=900)\n",
    "# lA\n",
    "# print(lA)\n",
    "# A_B = project_onto_face(A, l=lA)\n",
    "# print('Identified Profiles',A_B.sum())\n",
    "# Rn= Decompose(R_sa, A, A_B)\n",
    "# Rn = Demix(R_sa, A, A_B, MN)\n",
    "# print('demixed ratings',np.count_nonzero(Rn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74\n",
      "Identified Profiles 944.0\n",
      "Profile1    205.0\n",
      "Profile2    172.0\n",
      "Profile3    431.0\n",
      "Profile4    136.0\n",
      "dtype: float64\n",
      "(0.8509, 0.764, 0.3582, 0.7653, 0.0, 0.977, 0, 0.9987)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser</th>\n",
       "      <th>TwoUser</th>\n",
       "      <th>ThreeUser</th>\n",
       "      <th>FourUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>singleUser</th>\n",
       "      <td>542</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoUser</th>\n",
       "      <td>91</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThreeUser</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FourUser</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            singleUser  TwoUser  ThreeUser  FourUser\n",
       "singleUser         542       84          6         0\n",
       "TwoUser             91       48          7         0\n",
       "ThreeUser            3        2          0         0\n",
       "FourUser             1        0          0         0"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=5000, lambda_w=1.001, lambda_h=1.001\n",
    "lA = 0.74\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(UserIdentificationMeasure(SA, A_B))\n",
    "Confusion(SA,A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n",
      "Identified Profiles 943.0\n",
      "Profile1    205.0\n",
      "Profile2    171.0\n",
      "Profile3    430.0\n",
      "Profile4    137.0\n",
      "dtype: float64\n",
      "(0.8556, 0.7717, 0.3704, 0.7691, 0.0, 0.9783, 0, 0.9987)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser</th>\n",
       "      <th>TwoUser</th>\n",
       "      <th>ThreeUser</th>\n",
       "      <th>FourUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>singleUser</th>\n",
       "      <td>545</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoUser</th>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThreeUser</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FourUser</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            singleUser  TwoUser  ThreeUser  FourUser\n",
       "singleUser         545       81          6         0\n",
       "TwoUser             90       50          6         0\n",
       "ThreeUser            1        4          0         0\n",
       "FourUser             1        0          0         0"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=1000, lambda_w=1.001, lambda_h=1.001\n",
    "lA = 0.735\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(UserIdentificationMeasure(SA, A_B))\n",
    "Confusion(SA,A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.735\n",
      "Identified Profiles 944.0\n",
      "Profile1    207.0\n",
      "Profile2    172.0\n",
      "Profile3    426.0\n",
      "Profile4    139.0\n",
      "dtype: float64\n",
      "(0.8587, 0.7768, 0.3806, 0.773, 0.0769, 0.9796, 0, 0.9987)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser</th>\n",
       "      <th>TwoUser</th>\n",
       "      <th>ThreeUser</th>\n",
       "      <th>FourUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>singleUser</th>\n",
       "      <td>547</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoUser</th>\n",
       "      <td>89</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThreeUser</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FourUser</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            singleUser  TwoUser  ThreeUser  FourUser\n",
       "singleUser         547       79          6         0\n",
       "TwoUser             89       51          6         0\n",
       "ThreeUser            1        3          1         0\n",
       "FourUser             0        1          0         0"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_iter=1000, lambda_w=1.01, lambda_h=1.001\n",
    "lA = 0.735\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())\n",
    "print(UserIdentificationMeasure(SA, A_B))\n",
    "Confusion(SA,A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.743\n",
      "Identified Profiles 943.0\n",
      "Profile1    182.0\n",
      "Profile2    207.0\n",
      "Profile3    413.0\n",
      "Profile4    141.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "max_iter=500, lambda_w=1.1, lambda_h=1.01\n",
    "lA = 0.743\n",
    "print(lA)\n",
    "A_B = project_onto_face(A, l=lA)\n",
    "print('Identified Profiles',A_B.sum())\n",
    "# frame working for ilustraticon\n",
    "label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "print(A_B_df.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8469, 0.7602, 0.3538, 0.7653, 0.0769, 0.9796, 0.0, 0.9974)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser</th>\n",
       "      <th>TwoUser</th>\n",
       "      <th>ThreeUser</th>\n",
       "      <th>FourUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>singleUser</th>\n",
       "      <td>542</td>\n",
       "      <td>82</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoUser</th>\n",
       "      <td>95</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThreeUser</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FourUser</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            singleUser  TwoUser  ThreeUser  FourUser\n",
       "singleUser         542       82          8         0\n",
       "TwoUser             95       46          4         1\n",
       "ThreeUser            3        1          1         0\n",
       "FourUser             0        1          0         0"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(UserIdentificationMeasure(SA, A_B))\n",
    "Confusion(SA,A_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser</th>\n",
       "      <th>TwoUser</th>\n",
       "      <th>ThreeUser</th>\n",
       "      <th>FourUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>singleUser</th>\n",
       "      <td>530</td>\n",
       "      <td>96</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoUser</th>\n",
       "      <td>99</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThreeUser</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FourUser</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            singleUser  TwoUser  ThreeUser  FourUser\n",
       "singleUser         530       96          6         0\n",
       "TwoUser             99       43          4         0\n",
       "ThreeUser            3        1          1         0\n",
       "FourUser             1        0          0         0"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Confusion(SA,A_B) , lA = 0.93, iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>singleUser</th>\n",
       "      <th>TwoUser</th>\n",
       "      <th>ThreeUser</th>\n",
       "      <th>FourUser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>singleUser</th>\n",
       "      <td>530</td>\n",
       "      <td>92</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoUser</th>\n",
       "      <td>103</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThreeUser</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FourUser</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            singleUser  TwoUser  ThreeUser  FourUser\n",
       "singleUser         530       92         10         0\n",
       "TwoUser            103       38          5         0\n",
       "ThreeUser            3        2          0         0\n",
       "FourUser             1        0          0         0"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Confusion(SA,A_B) , 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 3], [53, 278])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IdentifiedMapping(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.5, 0.2, 0. , ..., 0. , 0. , 0. ]),\n",
       " array([4., 0., 0., ..., 0., 0., 0.]),\n",
       " array([3.5, 3.8, 0. , ..., 0. , 0. , 0. ]),\n",
       " array([3., 4., 0., ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rn[2],R[53],Rn[3],R[278]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.1265409 , 0.07398889, 0.470901  , 0.58146732]),\n",
       " array([0., 0., 1., 1.]))"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[2], A_B[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(Rn[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pairs = ComputeSimilarity(A_B,Rn,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pairs_df = pd.DataFrame(best_pairs, columns=['user_idenified','user_gt','ratings similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_idenified</th>\n",
       "      <th>user_gt</th>\n",
       "      <th>ratings similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>942</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "      <td>0.7304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>328</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_idenified  user_gt  ratings similarity\n",
       "0               0      942              1.0000\n",
       "1               1      430              1.0000\n",
       "2               2      278              0.7304\n",
       "3               3       53              0.7304\n",
       "4               4      328              1.0000"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_pairs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9518, 124557)"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(best_pairs_df['ratings similarity'].mean(),4), np.count_nonzero(Rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107086"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(Rn.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ratings 100000\n"
     ]
    }
   ],
   "source": [
    "print('number of ratings', np.count_nonzero(R)+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD4_WC\n",
      "Identified Profiles 943.0\n",
      "Profile1    165.0\n",
      "Profile2    196.0\n",
      "Profile3    439.0\n",
      "Profile4    143.0\n",
      "dtype: float64\n",
      "demixed ratings 943\n",
      "Similarity: 0.9672\n",
      "UserIdentification (0.8307, 0.7321, 0.2932, 0.7436, 0.0769, 0.9796, 0, 0.9987)\n",
      "identified ratings 106098\n",
      "Applying recommender: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE R_SAD4_WC : 1.1112\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE Reconstructed : 1.0899\n",
      "_____________________________________\n",
      "dataset_name: R_SAD_NC\n",
      "Identified Profiles 943.0\n",
      "Profile1    165.0\n",
      "Profile2    211.0\n",
      "Profile3    434.0\n",
      "Profile4    133.0\n",
      "dtype: float64\n",
      "demixed ratings 943\n",
      "Similarity: 0.976\n",
      "UserIdentification (0.8231, 0.7178, 0.2643, 0.728, 0.1, 0.9834, 0, 0.9987)\n",
      "identified ratings 107304\n",
      "Applying recommender: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE R_SAD_NC : 0.9507\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE Reconstructed : 0.9814\n",
      "_____________________________________\n",
      "dataset_name: R_SAD_4Clusters\n",
      "Identified Profiles 944.0\n",
      "Profile1    199.0\n",
      "Profile2    150.0\n",
      "Profile3    441.0\n",
      "Profile4    154.0\n",
      "dtype: float64\n",
      "demixed ratings 944\n",
      "Similarity: 0.9565\n",
      "UserIdentification (0.8448, 0.7551, 0.3383, 0.7589, 0.0, 0.9783, 0.0, 0.9974)\n",
      "identified ratings 107086\n",
      "Applying recommender: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE R_SAD_4Clusters : 1.2513\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE Reconstructed : 1.1642\n",
      "_____________________________________\n"
     ]
    }
   ],
   "source": [
    "AllDataSets = [R_SAD4_WC, R_SAD_NC, R_SAD_4Clusters]\n",
    "\n",
    "# Iterate over the datasets and import them\n",
    "for dataset in AllDataSets:\n",
    "    R_sa, SA, lA, dataset_name = dataset()\n",
    "    print('dataset_name:',dataset_name)\n",
    "    A , MN = BinaryNimfaSolver(R_sa, M)\n",
    "    A_B = project_onto_face(A, l=lA)\n",
    "    print('Identified Profiles',A_B.sum())\n",
    "    # frame working for ilustraticon\n",
    "    label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "    A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "    print(A_B_df.sum())\n",
    "    Rn = Demix(R_sa, A, A_B, MN)\n",
    "    Rn = Rn.astype(int)\n",
    "    print('demixed ratings', Rn.shape[0])\n",
    "    best_pairs = ComputeSimilarity(A_B, Rn, R)\n",
    "    MeanSimilarity = np.round(np.array(best_pairs)[:,2].mean(),4)\n",
    "    print('Similarity:', MeanSimilarity)\n",
    "    print(\"UserIdentification\",UserIdentificationMeasure(SA, A_B))\n",
    "    print('identified ratings', np.count_nonzero(Rn))\n",
    "    print('Applying recommender: Baseline')\n",
    "    print('RMSE',dataset_name,':', ComputeRMSE(R_sa))    \n",
    "    print('RMSE Reconstructed',':', ComputeRMSE(Rn))\n",
    "    print('_____________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD4_WC\n",
      "Identified Profiles 943.0\n",
      "Profile1    165.0\n",
      "Profile2    196.0\n",
      "Profile3    439.0\n",
      "Profile4    143.0\n",
      "dtype: float64\n",
      "Similarity: 0.9643363732767763\n",
      "UserIdentification (0.8307, 0.7321, 0.2932, 0.7436, 0.0769, 0.9796, 0, 0.9987)\n",
      "identified ratings 123881\n",
      "Applying recommender: CoClustering:\n",
      "RMSE R_SAD4_WC : 1.1305\n",
      "RMSE Reconstructed : 0.9372\n",
      "_____________________________________\n",
      "dataset_name: R_SAD_NC\n",
      "Identified Profiles 943.0\n",
      "Profile1    165.0\n",
      "Profile2    211.0\n",
      "Profile3    434.0\n",
      "Profile4    133.0\n",
      "dtype: float64\n",
      "Similarity: 0.9737392364793214\n",
      "UserIdentification (0.8231, 0.7178, 0.2643, 0.728, 0.1, 0.9834, 0, 0.9987)\n",
      "identified ratings 122599\n",
      "Applying recommender: CoClustering:\n",
      "RMSE R_SAD_NC : 0.9675\n",
      "RMSE Reconstructed : 0.8453\n",
      "_____________________________________\n",
      "dataset_name: R_SAD_4Clusters\n",
      "Identified Profiles 944.0\n",
      "Profile1    199.0\n",
      "Profile2    150.0\n",
      "Profile3    441.0\n",
      "Profile4    154.0\n",
      "dtype: float64\n",
      "Similarity: 0.9530648992576882\n",
      "UserIdentification (0.8448, 0.7551, 0.3383, 0.7589, 0.0, 0.9783, 0.0, 0.9974)\n",
      "identified ratings 124383\n",
      "Applying recommender: CoClustering:\n",
      "RMSE R_SAD_4Clusters : 1.2641\n",
      "RMSE Reconstructed : 1.0161\n",
      "_____________________________________\n"
     ]
    }
   ],
   "source": [
    "AllDataSets = [R_SAD4_WC, R_SAD_NC, R_SAD_4Clusters]\n",
    "\n",
    "# Iterate over the datasets and import them\n",
    "for dataset in AllDataSets:\n",
    "    R_sa, SA, lA, dataset_name = dataset()\n",
    "    print('dataset_name:',dataset_name)\n",
    "    A , MN = BinaryNimfaSolver(R_sa, M)\n",
    "    A_B = project_onto_face(A, l=lA)\n",
    "    print('Identified Profiles',A_B.sum())\n",
    "    # frame working for ilustraticon\n",
    "    label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "    A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "    print(A_B_df.sum())\n",
    "    Rn = Decompose(R_sa, A, A_B)\n",
    "    best_pairs = ComputeSimilarity(A_B,Rn,R)\n",
    "    MeanSimilarity = np.round(np.array(best_pairs)[:,2].mean(),4)\n",
    "    print('Similarity:', MeanSimilarity)\n",
    "    print(\"UserIdentification\",UserIdentificationMeasure(SA, A_B))\n",
    "    print('identified ratings', np.count_nonzero(Rn))\n",
    "    print('Applying recommender: CoClustering:')\n",
    "    print('RMSE',dataset_name,':', ComputeRMSE(R_sa))    \n",
    "    print('RMSE Reconstructed',':', ComputeRMSE(Rn))\n",
    "    print('_____________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD4_WC\n",
      "Identified Profiles 943.0\n",
      "Profile1    165.0\n",
      "Profile2    196.0\n",
      "Profile3    439.0\n",
      "Profile4    143.0\n",
      "dtype: float64\n",
      "Similarity: 0.9643\n",
      "UserIdentification (0.8307, 0.7321, 0.2932, 0.7436, 0.0769, 0.9796, 0, 0.9987)\n",
      "identified ratings 123881\n",
      "Applying recommender: KNNBaseline\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE R_SAD4_WC : 1.1015\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE Reconstructed : 0.9048\n",
      "_____________________________________\n",
      "dataset_name: R_SAD_NC\n",
      "Identified Profiles 943.0\n",
      "Profile1    165.0\n",
      "Profile2    211.0\n",
      "Profile3    434.0\n",
      "Profile4    133.0\n",
      "dtype: float64\n",
      "Similarity: 0.9737\n",
      "UserIdentification (0.8231, 0.7178, 0.2643, 0.728, 0.1, 0.9834, 0, 0.9987)\n",
      "identified ratings 122599\n",
      "Applying recommender: KNNBaseline\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE R_SAD_NC : 0.9376\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE Reconstructed : 0.8103\n",
      "_____________________________________\n",
      "dataset_name: R_SAD_4Clusters\n",
      "Identified Profiles 944.0\n",
      "Profile1    199.0\n",
      "Profile2    150.0\n",
      "Profile3    441.0\n",
      "Profile4    154.0\n",
      "dtype: float64\n",
      "Similarity: 0.9531\n",
      "UserIdentification (0.8448, 0.7551, 0.3383, 0.7589, 0.0, 0.9783, 0.0, 0.9974)\n",
      "identified ratings 124383\n",
      "Applying recommender: KNNBaseline\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE R_SAD_4Clusters : 1.2393\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE Reconstructed : 0.9839\n",
      "_____________________________________\n"
     ]
    }
   ],
   "source": [
    "AllDataSets = [R_SAD4_WC, R_SAD_NC, R_SAD_4Clusters]\n",
    "\n",
    "# Iterate over the datasets and import them\n",
    "for dataset in AllDataSets:\n",
    "    R_sa, SA, lA, dataset_name = dataset()\n",
    "    print('dataset_name:',dataset_name)\n",
    "    A , MN = BinaryNimfaSolver(R_sa, M)\n",
    "    A_B = project_onto_face(A, l=lA)\n",
    "    print('Identified Profiles',A_B.sum())\n",
    "    # frame working for ilustraticon\n",
    "    label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "    A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "    print(A_B_df.sum())\n",
    "    Rn = Decompose(R_sa, A, A_B)\n",
    "    best_pairs = ComputeSimilarity(A_B,Rn,R)\n",
    "    MeanSimilarity = np.round(np.array(best_pairs)[:,2].mean(),4)\n",
    "    print('Similarity:', MeanSimilarity)\n",
    "    print(\"UserIdentification\",UserIdentificationMeasure(SA, A_B))\n",
    "    print('identified ratings', np.count_nonzero(Rn))\n",
    "    print('Applying recommender: KNNBaseline')\n",
    "    print('RMSE',dataset_name,':', ComputeRMSE(R_sa))    \n",
    "    print('RMSE Reconstructed',':', ComputeRMSE(Rn))\n",
    "    print('_____________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: R_SAD4_WC\n",
      "Identified Profiles 943.0\n",
      "Profile1    165.0\n",
      "Profile2    196.0\n",
      "Profile3    439.0\n",
      "Profile4    143.0\n",
      "dtype: float64\n",
      "Similarity: 0.9643\n",
      "UserIdentification (0.8307, 0.7321, 0.2932, 0.7436, 0.0769, 0.9796, 0, 0.9987)\n",
      "identified ratings 123881\n",
      "Applying recommender: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE R_SAD4_WC : 1.111\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE Reconstructed : 0.925\n",
      "_____________________________________\n",
      "dataset_name: R_SAD_NC\n",
      "Identified Profiles 943.0\n",
      "Profile1    165.0\n",
      "Profile2    211.0\n",
      "Profile3    434.0\n",
      "Profile4    133.0\n",
      "dtype: float64\n",
      "Similarity: 0.9737\n",
      "UserIdentification (0.8231, 0.7178, 0.2643, 0.728, 0.1, 0.9834, 0, 0.9987)\n",
      "identified ratings 122599\n",
      "Applying recommender: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE R_SAD_NC : 0.9511\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE Reconstructed : 0.8345\n",
      "_____________________________________\n",
      "dataset_name: R_SAD_4Clusters\n",
      "Identified Profiles 944.0\n",
      "Profile1    199.0\n",
      "Profile2    150.0\n",
      "Profile3    441.0\n",
      "Profile4    154.0\n",
      "dtype: float64\n",
      "Similarity: 0.9531\n",
      "UserIdentification (0.8448, 0.7551, 0.3383, 0.7589, 0.0, 0.9783, 0.0, 0.9974)\n",
      "identified ratings 124383\n",
      "Applying recommender: Baseline\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE R_SAD_4Clusters : 1.2511\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "RMSE Reconstructed : 1.0051\n",
      "_____________________________________\n"
     ]
    }
   ],
   "source": [
    "# AllDataSets = [R_SAD3, R_SAD4, R_SAD5, R_SAD_NC]\n",
    "AllDataSets = [R_SAD4_WC, R_SAD_NC, R_SAD_4Clusters]\n",
    "\n",
    "# Iterate over the datasets and import them\n",
    "for dataset in AllDataSets:\n",
    "    R_sa, SA, lA, dataset_name = dataset()\n",
    "    print('dataset_name:',dataset_name)\n",
    "    A , MN = BinaryNimfaSolver(R_sa, M)\n",
    "    A_B = project_onto_face(A, l=lA)\n",
    "    print('Identified Profiles',A_B.sum())\n",
    "    # frame working for ilustraticon\n",
    "    label = ['Profile1','Profile2', 'Profile3','Profile4']\n",
    "    A_B_df = pd.DataFrame(A_B,columns=label)\n",
    "    print(A_B_df.sum())\n",
    "    Rn = Demix(R_sa, A, A_B, MN)\n",
    "    best_pairs = ComputeSimilarity(A_B, Rn, R)\n",
    "    MeanSimilarity = np.round(np.array(best_pairs)[:,2].mean(),4)\n",
    "    print('Similarity:', MeanSimilarity)\n",
    "    print(\"UserIdentification\",UserIdentificationMeasure(SA, A_B))\n",
    "    print('identified ratings', np.count_nonzero(Rn))\n",
    "    print('Applying recommender: Baseline')\n",
    "    print('RMSE',dataset_name,':', ComputeRMSE(R_sa))    \n",
    "    print('RMSE Reconstructed',':', ComputeRMSE(Rn))\n",
    "    print('_____________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllSolvers = [BinaryNimfaSolver, NimfaSolver,cvxSolver, GD_solver]\n",
    "# Iterate over the solvers\n",
    "for solver in AllSolvers:\n",
    "    A = solver(R_sa, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing M to use in partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d,e = [],[],[],[],[]\n",
    "# pd.DataFrame(M_B).to_csv('InputData/M_B.csv')\n",
    "L = np.linspace(0,1,10)\n",
    "for l in L:\n",
    "    M_B= BinarizingM(M,l=l)\n",
    "    a.append(np.count_nonzero(M_B,axis=1)[0])\n",
    "    b.append(np.count_nonzero(M_B,axis=1)[1])\n",
    "    c.append(np.count_nonzero(M_B,axis=1)[2])\n",
    "    d.append(np.count_nonzero(M_B,axis=1)[3])\n",
    "    e.append(np.sum(M_B))\n",
    "# To analyze M_B: overally our movies have how many characters\n",
    "# print(np.count_nonzero(M_B,axis=1), np.sum(M_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L,a)\n",
    "plt.plot(L,b)\n",
    "plt.plot(L,c)\n",
    "plt.plot(L,d)\n",
    "plt.plot(L,e)\n",
    "\n",
    "plt.xlabel('l')\n",
    "plt.ylabel('Identified Character Movies')\n",
    "plt.gca().grid(which='minor')\n",
    "plt.title('Movie Binarizing')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.linspace(0.7,0.9,10)\n",
    "AB,NI = [],[]\n",
    "for lA in L:\n",
    "    A_hat_B = project_onto_face(A,l=lA)\n",
    "    n_identified = A_hat_B.sum()\n",
    "    AB.append(A_hat_B)\n",
    "    NI.append(n_identified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(L,AB)\n",
    "plt.plot(L,NI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatasetSelection():\n",
    "    print(\"Executing Task 2\")\n",
    "def WeightingSelection():\n",
    "    print(\"Executing Task 3\")\n",
    "def SolverSelection():\n",
    "    for\n",
    "    print(\"choose the solver and desired range\")\n",
    "def Assessment():\n",
    "    print(\"running the below code\")\n",
    "\n",
    "\n",
    "# Create a list of tasks\n",
    "all_tasks = [task1, task2, task3]\n",
    "\n",
    "# Iterate over the tasks and execute them\n",
    "for task in all_tasks:\n",
    "    task()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing Solver\n",
    "\n",
    "# solver = 'GD'\n",
    "# A = GD_solver(R_sa,M)\n",
    "\n",
    "# solver = 'cvx'\n",
    "# A = cvxSolver(R_sa,M)\n",
    "\n",
    "# solver = 'nmf'\n",
    "A = NimfaSolver(R_sa, k=4)\n",
    "\n",
    "# solver = 'bmf'\n",
    "# A = BinaryNimfaSolver(R_sa, M)\n",
    "\n",
    "# Binarizing with different l\n",
    "## R_sa_WC\n",
    "#M:Wuhr\n",
    "    # *lM = 0.8\n",
    "    # GD *lA = 0.9775\n",
    "    # cvx*lA = 0.77\n",
    "    # nmf*lA = 0.76\n",
    "    # bmf*lA = 0.77\n",
    "#M:Clu\n",
    "    # *lM = 0.2\n",
    "    # GD  *lA = 0.53\n",
    "    # cvx *lA = 0.7\n",
    "    # nmf*lA = 0.775\n",
    "    # bmf*lA = 0.77\n",
    "    \n",
    "## R_sa_NC\n",
    "#M:Wuhr\n",
    "    # *lM = 0.8\n",
    "    # GD *lA = 0.9775\n",
    "    # cvx*lA = 0.74\n",
    "    # nmf*lA = 0.77\n",
    "    # bmf*lA = 0.9\n",
    "#M:Clu\n",
    "    # *lM = 0.2\n",
    "    # GD  *lA = 0.535\n",
    "    # cvx *lA = 0.31\n",
    "    # nmf*lA = 0.775\n",
    "    # bmf*lA = 0.77\n",
    "    \n",
    "# result = []\n",
    "# for lM in [0.18,0.2,0.22]:\n",
    "\n",
    "for lM in [0.7,0.8,0.9]:\n",
    "    lM = lM\n",
    "    M_B= BinarizingM(M,l=lM)\n",
    "    for lA in np.linspace(0.76,0.78,10):\n",
    "        A_hat_B = project_onto_face(A,l=lA)\n",
    "        n_identified = A_hat_B.sum()\n",
    "        #Reconstruction\n",
    "        Rr = MatrixReconstruction(R_sa,A_hat_B,M_B)\n",
    "        # Assesment\n",
    "        RMSE = ComputeRMSE(Rr)\n",
    "        precision1, accuracy1, precision2, accuracy2,precision3, accuracy3, precision4, accuracy4 = UserIdentificationMeasure(SA, A_hat_B)\n",
    "        data = [dataset_name, weighting, solver, lM, lA, n_identified, RMSE, (Rr != 0).sum(), precision1, accuracy1, precision2, accuracy2,precision3, accuracy3, precision4, accuracy4]\n",
    "        result.append(data)\n",
    "        \n",
    "col=['datset name','weighting','solver', 'lM', 'lA', 'n_identified', 'RMSE','#ratings'\n",
    "         ,'precision1','accuracy1','precision2','accuracy2'\n",
    "         ,'precision3','accuracy3','precision4','accuracy4']\n",
    "Result = pd.DataFrame(result,columns=col)\n",
    "pd.DataFrame(Result).to_csv('InputData/Result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing Solver\n",
    "solver = 'bmf'\n",
    "A = BinaryNimfaSolver(R_sa, M)\n",
    "\n",
    "result2 = []\n",
    "for lM in [0.18,0.2,0.22]:\n",
    "    lM = lM\n",
    "    M_B= BinarizingM(M,l=lM)\n",
    "    for lA in np.linspace(0.76,0.78,10):\n",
    "        A_hat_B = project_onto_face(A,l=lA)\n",
    "        n_identified = A_hat_B.sum()\n",
    "        #Reconstruction\n",
    "        Rr = MatrixReconstruction(R_sa,A_hat_B,M_B)\n",
    "        # Assesment\n",
    "        RMSE = ComputeRMSE(Rr)\n",
    "        precision1, accuracy1, precision2, accuracy2,precision3, accuracy3, precision4, accuracy4 = UserIdentificationMeasure(SA, A_hat_B)\n",
    "        data = [dataset_name, weighting, solver, lM, lA, n_identified, RMSE, (Rr != 0).sum(), precision1, accuracy1, precision2, accuracy2,precision3, accuracy3, precision4, accuracy4]\n",
    "        result2.append(data)\n",
    "        \n",
    "col=['datset name','weighting','solver', 'lM', 'lA', 'n_identified', 'RMSE','#ratings'\n",
    "         ,'precision1','accuracy1','precision2','accuracy2'\n",
    "         ,'precision3','accuracy3','precision4','accuracy4']\n",
    "Result2 = pd.DataFrame(result2,columns=col)\n",
    "pd.DataFrame(Result2).to_csv('InputData/Result2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent Solver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Main Gradient descend solver\n",
    "def GD_solver(V, H, p=1.1, max_iteration=20):\n",
    "    '''\n",
    "    V : is a mxn array\n",
    "    H : is a kxn array\n",
    "    '''\n",
    "    m, n = V.shape   # Number of users and movies\n",
    "    O = np.array(V != 0,dtype='float')   # Producing Observation matrix \n",
    "    k = H.shape[0]   # Number of features\n",
    "    W = np.zeros((m,k),dtype=float)   # Initial point X0\n",
    "    f = 0   # Initial objective value\n",
    "    sequence = []   # for saving what happen in the iterations\n",
    "    # Normalization\n",
    "    for t in range(n):\n",
    "        s = H.T[t].sum()\n",
    "        if s == 0:\n",
    "            s=1\n",
    "        H.T[t] = H.T[t]/s\n",
    "    # Main\n",
    "    for iteration in range(max_iteration+1):\n",
    "        f = (1/2) * np.linalg.norm((V - O*np.dot(W, H)), 'fro')**2 + (p/2)* np.linalg.norm((np.multiply(W,W)-W), 'fro')**2\n",
    "        g = -1*(V - O*np.dot(W, H)).dot(H.T) + p * (2*W-np.ones((m,k)))*(np.multiply(W,W)-W)\n",
    "        sequence.append([iteration, W, f, g])\n",
    "        improvment =  sequence[iteration][2] - sequence[iteration-1][2]\n",
    "        #stoping criterion\n",
    "        if improvment > 0 or  iteration >= max_iteration:\n",
    "            break       \n",
    "        # Updating\n",
    "        alpha = 1/(1+iteration)\n",
    "        W = W-(alpha*g)\n",
    "        p = p * p\n",
    "        # Normalization\n",
    "        for j in range(W.shape[0]):\n",
    "            total = W[j].sum()\n",
    "            if total ==0:\n",
    "                total = 1\n",
    "            W[j] = W[j]/total\n",
    "        return W\n",
    "#     return W, sequence\n",
    "#     return col_balancing(W), sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, temperature=1.0):\n",
    "    \"\"\"Compute softmax values for each set of scores in x.\"\"\"\n",
    "    x = np.array(x)\n",
    "    x_scaled = x / temperature  # Scale by temperature\n",
    "    e_x = np.exp(x_scaled - np.max(x_scaled))  # subtract the max for numerical stability\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_softened = np.reshape(softmax(A, temperature=1.5),(784,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying softmax or other binarizing methods on A: account feature matrix and analysing UserIdentification (Confusion Matrix), it became clear that the best method for producing A_B: account membership matrix is my Projection onto face function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_balancing(B = 'array_like_matrix'):\n",
    "    m,k= B.shape\n",
    "    miu= B.mean()\n",
    "    b = [0]*k\n",
    "    for i in range(k):\n",
    "        b[i]= miu - B[:,i].mean()\n",
    "        B[:,i] = B[:,i]+b[i]\n",
    "        B[B<0]=0\n",
    "    return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To reconstruct data matrix to incorporate identified users\n",
    "# first partition R  into K submatrix Like Pimentel Full\n",
    "# R[k] is the in omega_M[k]: we have the the desirable colomn indices of R[k]\n",
    "def MatrixReconstruction(R_sa= 'mixture matrix', A_hat_B = 'account membership matrix', M_B = 'movie membership matrix'):\n",
    "    '''\n",
    "    partition the shared rating matrix to characters ratanings\n",
    "    '''\n",
    "    # nc : number of charactes\n",
    "    nc = M_B.shape[0]\n",
    "    \n",
    "    omega_A = []\n",
    "    for k in range(nc):\n",
    "        omega_A.append(list(np.unique(np.where(A_hat_B[:,k]>0))))\n",
    "    \n",
    "    omega_M_B = []\n",
    "    for k in range(nc):\n",
    "        omega_M_B.append(list(np.unique(np.where(M_B[k,:]>0))))\n",
    "    \n",
    "    # Rp[nc] : the nc partition of R\n",
    "    Rp = [np.zeros((R_sa.shape[0],R_sa.shape[1]),dtype='int') for i in range(nc)]\n",
    "    for k in range(nc):\n",
    "        for i in omega_A[k]:\n",
    "            for j in omega_M_B[k]:\n",
    "                Rp[k][i][j]= R_sa[i,j]\n",
    "    \n",
    "    # Reconstructing ratings matrix\n",
    "    Rr = []   # reconstructed Rating matrix\n",
    "    counter = 0\n",
    "    identified_users_from_a_are = [[] for i in range(A_hat_B.shape[0])]\n",
    "    for r in range(A_hat_B.shape[0]):\n",
    "        pos = list(np.unique(np.where(A_hat_B[r]>0)))\n",
    "        for i in pos:\n",
    "            Rr.append(Rp[i][r])\n",
    "            identified_users_from_a_are[r].append(r+counter)\n",
    "            counter = counter+1\n",
    "        counter = counter-1\n",
    "    Rr = np.array(Rr)\n",
    "    #return Rp, identified_users_from_a_are\n",
    "    return Rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To compute the taste of each user type in each account\n",
    "# To be computed for each account\n",
    "def AccountReRating(A= 'account feature matrix', A_B, MN='movie feature matrix', a=\"account index\"):\n",
    "    K = A[a].shape[1]\n",
    "    n = MN.shape[1]\n",
    "    user_share_of_type= np.zeros((K,n))\n",
    "    for k in range(K):\n",
    "        for j in range(n):\n",
    "            user_share_of_type[k,j] = A[a,k]*MN[k,j]\n",
    "    user_share_of_type = user_share_of_type.reshape(1, -1) # turning the vector to row matrix\n",
    "    normalized_user_share_of_type = normalize(user_share_of_type,axis=1, norm='l1')\n",
    "    # Scaling ratings to [1, 5]\n",
    "    rr = np.zeros(K) # new ratings\n",
    "    for k in range(K):\n",
    "        rr[k] = 1 + 4 * normalized_user_share_of_type[:, k]\n",
    "    return rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(A_hat_B).to_csv('InputData/A_hat_B.csv')\n",
    "\n",
    "# frame working for ilustration\n",
    "label = ['Male','Female', 'Children','Family']\n",
    "A_hat_B_df = pd.DataFrame(A_hat_B,columns=label)\n",
    "A_hat_B_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#ratings Rsa_NC\",n_ratings)\n",
    "print(\"#ratings Rsa_WC\",97531)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1():\n",
    "    print(\"Executing Task 1\")\n",
    "\n",
    "def task2():\n",
    "    print(\"Executing Task 2\")\n",
    "\n",
    "def task3():\n",
    "    print(\"Executing Task 3\")\n",
    "\n",
    "# Create a list of tasks\n",
    "all_tasks = [task1, task2, task3]\n",
    "\n",
    "# Iterate over the tasks and execute them\n",
    "for task in all_tasks:\n",
    "    task()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_R_SVD = 0.9377, 6\n",
    "RMSE_R_BaselineOnly = 0.9457, 0.5\n",
    "RMSE_RCoClustering = 0.9693, 3\n",
    "RMSE_R_KNNBaseline = 0.9326, 7\n",
    "\n",
    "RMSE_Rsa_NC_SVD = 0.9438, 6\n",
    "RMSE_Rsa_NC_BaselineOnly = 0.9509, 0.5\n",
    "RMSE_Rsa_NC_CoClustering = 0.9703, 3\n",
    "RMSE_Rsa_NC_KNNBaseline = 0.9381, 6\n",
    "\n",
    "RMSE_Rsa_WC_SVD = 1.1067, 6\n",
    "RMSE_Rsa_WC_BaselineOnly = 1.1107, 0.5\n",
    "RMSE_Rsa_WC_CoClustering = 1.1331, 3\n",
    "RMSE_Rsa_WC_KNNBaseline = 1.1011, 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Torch solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Assuming R and M are given as numpy arrays or torch tensors\n",
    "# Convert them to torch tensors if they are not already\n",
    "R = torch.tensor(R_sa, dtype=torch.float32, requires_grad=False)\n",
    "M = torch.tensor(M, dtype=torch.float32, requires_grad=False)\n",
    "solver = 'torch'\n",
    "\n",
    "# Initialize A with random values\n",
    "A = torch.randn((R.shape[0], M.shape[0]), dtype=torch.float32, requires_grad=True)\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SGD([A], lr=0.01)\n",
    "n_iterations = 1000\n",
    "for _ in range(n_iterations):\n",
    "    optimizer.zero_grad() \n",
    "    # Compute the prediction\n",
    "    prediction = torch.matmul(A, M)   \n",
    "    # Compute the loss (Frobenius norm of the difference)\n",
    "    loss = (R - prediction).norm()  \n",
    "    # Backpropagation\n",
    "    loss.backward()    \n",
    "    # Update A\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Known Matrices\n",
    "R = R_sa.astype(np.float32)  # Example rating matrix R\n",
    "M = M.astype(np.float32)  # Example known movie feature matrix M\n",
    "# Constants for the dimensions of the matrices\n",
    "m, k, n = 784, 4, 1680  # m x k (X), k x n (M), m x n (R)\n",
    "\n",
    "\n",
    "\n",
    "# TensorFlow Dataset to manage batches of R\n",
    "dataset = tf.data.Dataset.from_tensor_slices(R)\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "# Prepare M as a constant tensor\n",
    "M_tensor = tf.constant(M, dtype=tf.float32)\n",
    "\n",
    "# Variable for X\n",
    "X = tf.Variable(tf.random.uniform([m, k], minval=0, maxval=1, dtype=tf.float32), trainable=True)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "# Loss function\n",
    "def loss_function(predicted, target):\n",
    "    return tf.reduce_mean(tf.square(predicted - target))\n",
    "\n",
    "# Training step function\n",
    "@tf.function\n",
    "def train_step(R_batch, indices):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get the corresponding batch of X based on indices\n",
    "        X_batch = tf.gather(X, indices, axis=0)\n",
    "        # Predict R using X_batch and M\n",
    "        R_pred = tf.matmul(X_batch, M_tensor)\n",
    "        # Calculate the loss\n",
    "        loss = loss_function(R_pred, R_batch)\n",
    "    # Get the gradients for X_batch\n",
    "    gradients = tape.gradient(loss, [X_batch])\n",
    "    # Apply gradients to the corresponding part of X\n",
    "    optimizer.apply_gradients([(tf.IndexedSlices(gradients[0], indices), X)])\n",
    "    return loss\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for step, R_batch in enumerate(dataset):\n",
    "        # Calculate batch indices\n",
    "        batch_indices = tf.range(step * 32, min((step + 1) * 32, m))\n",
    "        loss = train_step(R_batch, batch_indices)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Step {step}, Loss: {loss.numpy()}\")\n",
    "\n",
    "# Fetch the final value of X\n",
    "learned_X = X.numpy()\n",
    "print(\"Learned User Features X Shape:\", learned_X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network and DEEP solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# # Constants for the dimensions of the matrices\n",
    "# m, k, n = 784, 4, 1680  # m x k (X), k x n (M), m x n (R)\n",
    "\n",
    "# # Known Matrices\n",
    "# R = np.random.normal(size=(m, n)).astype(np.float32)  # Example rating matrix R\n",
    "# M = np.random.normal(size=(k, n)).astype(np.float32)  # Example known movie feature matrix M\n",
    "\n",
    "\n",
    "# Known Matrices\n",
    "R = R_sa.astype(np.float32)  # Example rating matrix R\n",
    "M = M.astype(np.float32)  # Example known movie feature matrix M\n",
    "# Constants for the dimensions of the matrices\n",
    "m, k, n = 784, 4, 1680  # m x k (X), k x n (M), m x n (R)\n",
    "\n",
    "\n",
    "# Prepare M as a constant tensor\n",
    "M_tensor = tf.constant(M, dtype=tf.float32)\n",
    "\n",
    "# Initialize X as a trainable variable\n",
    "X = tf.Variable(tf.random.uniform([m, k], 0, 1, dtype=tf.float32), trainable=True)\n",
    "\n",
    "# Custom layer to compute X * M\n",
    "class CustomMultiplyLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, M):\n",
    "        super(CustomMultiplyLayer, self).__init__()\n",
    "        self.M = M\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.M)\n",
    "\n",
    "# Build the model\n",
    "input_layer = tf.keras.Input(shape=(k,))\n",
    "multiply_layer = CustomMultiplyLayer(M_tensor)\n",
    "output = multiply_layer(input_layer)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Loss function to minimize the difference between R and X * M\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Fit model\n",
    "def train_model(X, R, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            R_pred = multiply_layer(X)  # X * M\n",
    "            loss = custom_loss(R, R_pred)\n",
    "        grads = tape.gradient(loss, [X])\n",
    "        optimizer.apply_gradients(zip(grads, [X]))\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")\n",
    "\n",
    "# Call the training function\n",
    "train_model(X, R)\n",
    "\n",
    "# Retrieve the learned user features matrix X\n",
    "learned_X = X.numpy()\n",
    "print(\"Learned User Features X Shape:\", learned_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lA = 0.7\n",
    "A_hat_B = project_onto_face(A,l=lA)\n",
    "A_hat_B.sum()\n",
    "n_identified = A_hat_B.sum()\n",
    "print(n_identified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rr = []   # reconstructed Rating matrix\n",
    "counter = 0\n",
    "identified_users_from_a_are = [[] for i in range(A_hat_B.shape[0])]\n",
    "for r in range(A_hat_B.shape[0]):\n",
    "    pos = list(np.unique(np.where(A_hat_B[r]>0)))\n",
    "    for i in pos:\n",
    "        Rr.append(Rp[i][r])\n",
    "        identified_users_from_a_are[r].append(r+counter)\n",
    "        counter = counter+1\n",
    "    counter = counter-1\n",
    "Rr = np.array(Rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Rp[0]).to_csv('InputData/Rp0.csv')\n",
    "pd.DataFrame(Rp[1]).to_csv('InputData/Rp1.csv')\n",
    "pd.DataFrame(Rp[2]).to_csv('InputData/Rp2.csv')\n",
    "pd.DataFrame(Rp[3]).to_csv('InputData/Rp3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rr = []\n",
    "for r in range(A_hat_B.shape[0]):\n",
    "    pos = list(np.unique(np.where(A_hat_B[r]>0)))\n",
    "    for i in pos:\n",
    "        Rr.append(Rp[i][r])\n",
    "Rr = np.array(Rr)\n",
    "print(Rr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Rr).to_csv('InputData/Rr2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing identified_users_from_a_are variable to pass it to another notebook\n",
    "%store identified_users_from_a_are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Completing R_sa\n",
    "# Input\n",
    "matrix_to_be_completed = R_sa\n",
    "\n",
    "from matrix_completion import svt_solve, calc_unobserved_rmse\n",
    "\n",
    "I = np.identity(matrix_to_be_completed.shape[0])\n",
    "# Producing Observation matrix \n",
    "O = np.array(matrix_to_be_completed != 0,dtype='float')  \n",
    "\n",
    "# The best max_iterations is 3 and more than 6 do not work\n",
    "R_hat = svt_solve(matrix_to_be_completed, O,max_iterations=3)\n",
    "print(\"RMSE:\", calc_unobserved_rmse(I, matrix_to_be_completed.T, R_hat, O))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# frame working for ilustration\n",
    "label = ['Male','Female', 'Children','Family']\n",
    "# A_hat_df = pd.DataFrame(A_hat,columns=label)\n",
    "A_hat_B_df = pd.DataFrame(A_hat_B,columns=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Identified character ratio\n",
    "A_hat_B.sum()/943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_hat_B_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To analyze the shared accounts: overally how many characters are in aour accounts\n",
    "rowsum=[]\n",
    "for i in range(A_hat_B.shape[0]):\n",
    "    rowsum.append(A_hat_B[i,:].sum())\n",
    "plt.hist(rowsum,bins=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis for parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "L = np.linspace(0,1,100)\n",
    "for i in L:\n",
    "    a = project_onto_face(A_hat,l=i)\n",
    "    r = a.sum()/782\n",
    "    Y.append(r)\n",
    "    \n",
    "plt.plot(L,Y)\n",
    "plt.xlabel('l')\n",
    "plt.ylabel('Identified Characters per Account')\n",
    "plt.gca().grid(which='minor')\n",
    "# plt.title('Rating Consistency over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "L = np.linspace(0.8,1,100)\n",
    "for i in L:\n",
    "    a = project_onto_face(A_hat,l=i)\n",
    "    r = a.sum()/782\n",
    "    Y.append(r)\n",
    "    \n",
    "plt.plot(L,Y)\n",
    "plt.xlabel('l')\n",
    "plt.ylabel('Identified Characters per Account')\n",
    "plt.gca().grid(which='minor')\n",
    "# plt.title('Rating Consistency over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "L = np.linspace(0.97,1,100)\n",
    "for i in L:\n",
    "    a = project_onto_face(A_hat,l=i)\n",
    "    r = a.sum()/782\n",
    "    Y.append(r)\n",
    "    \n",
    "plt.plot(L,Y)\n",
    "plt.xlabel('l')\n",
    "plt.ylabel('Identified Characters per Account')\n",
    "plt.gca().grid(which='minor')\n",
    "# plt.title('Rating Consistency over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose the l parameter to be 0.975 emperically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,Y1,Y2 = [],[],[]\n",
    "# Z = []\n",
    "L = np.linspace(0,1,100)\n",
    "for i in L:\n",
    "    U_hat_B = project_onto_face(U_hat,l=i)\n",
    "    U_hat_B_M = R_Mix_map(U_hat_B)\n",
    "    U_hat_B_M[U_hat_B_M>0]=1\n",
    "    U_hat_B_sa = project_onto_face(U_hat_sa,l=i)\n",
    "    D = U_hat_B_M - U_hat_B_sa\n",
    "    e = np.count_nonzero(D)/np.sum(U_hat_B_sa,where=[U_hat_B_sa>0])\n",
    "    Y.append(e)\n",
    "    Y1.append(np.count_nonzero(U_hat_B_M))\n",
    "    Y2.append(np.count_nonzero(U_hat_B_sa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(U_hat_B_sa,where=[U_hat_B_sa>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(L,Y)\n",
    "plt.xlabel('l')\n",
    "plt.ylabel('NonConformity')\n",
    "plt.gca().grid(which='minor')\n",
    "# plt.title('Rating Consistency over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(L,Y1)\n",
    "plt.plot(L,Y2)\n",
    "# plt.ylim([0, 5])\n",
    "plt.xlabel('l')\n",
    "plt.ylabel('Identifeid Users')\n",
    "plt.gca().grid(which='minor')\n",
    "# plt.title('Rating Consistency over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Account Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_mix = len(sa1)+len(sa2)+len(sa3)+len(sa4)\n",
    "places = [i for i in range(m_mix)]\n",
    "np.random.seed(1337)\n",
    "random_places_in_R_mix = []\n",
    "for i in range(m_mix):\n",
    "    j = np.random.randint(0,len(places))\n",
    "    random_places_in_R_mix.append(places[j])\n",
    "    places.pop(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_Mix_map(Input):\n",
    "    R = pd.DataFrame(Input)\n",
    "    m,n = R.shape\n",
    "    U_mix = np.zeros((m_mix,n),dtype=float)\n",
    "    i=0\n",
    "    j=0\n",
    "\n",
    "    for counter in range(len(sa1)):\n",
    "        U_mix[random_places_in_R_mix[i]]=R.iloc[list(sa1)[j],:]\n",
    "        i = i+1\n",
    "        j = j+1\n",
    "\n",
    "    j=0\n",
    "    for counter in range(len(sa2)):\n",
    "        U_mix[random_places_in_R_mix[i]]=R.iloc[list(sa2[j])[0],:]+R.iloc[list(sa2[j])[1],:]\n",
    "        i = i+1\n",
    "        j = j+1\n",
    "\n",
    "    j=0    \n",
    "    for counter in range(len(sa3)):\n",
    "        U_mix[random_places_in_R_mix[i]]=R.iloc[list(sa3[j])[0],:]+R.iloc[list(sa3[j])[1],:]+R.iloc[list(sa3[j])[2],:]\n",
    "        i = i+1\n",
    "        j = j+1\n",
    "\n",
    "    j=0    \n",
    "    for counter in range(len(sa4)):\n",
    "        U_mix[random_places_in_R_mix[i]]=R.iloc[list(sa4[j])[0],:]+R.iloc[list(sa4[j])[1],:]+R.iloc[list(sa4[j])[2],:] +R.iloc[list(sa4[j])[3],:]\n",
    "        i = i+1\n",
    "        j = j+1\n",
    "        \n",
    "    return U_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_sa_manualy = R_Mix_map(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to be right = 0.\n",
    "np.count_nonzero(R_sa_manualy - R_sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To partition R  into K submatrix\n",
    "\n",
    "R[k] is the \n",
    "in omega_M[k]: we have the the desirable colomn indices of R[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every row of movie feature matrix, find the subset of colomn indecies that are nonzero\n",
    "# in fact we are finding the movies that have the feature of k and save it in the k-th element of omega_M list\n",
    "M = M_B\n",
    "K = M.shape[0]\n",
    "omega_M = []\n",
    "for k in range(K):\n",
    "    omega_M.append(list(np.unique(np.where(M[k,:]>0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining User feature indices for row indices of\n",
    "# for ex omega_U_sa[1] is the set of indices that found to be children\n",
    "K = A_hat_B.shape[1]\n",
    "omega_A = []\n",
    "for k in range(K):\n",
    "    omega_A.append(list(np.unique(np.where(A_hat_B[:,k]>0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = R_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_k_0 =np.zeros((len(omega_A[0]),len(omega_M[0])))\n",
    "for i in range(len(omega_A[0])):\n",
    "    for j in range(len(omega_M[0])):\n",
    "        R_k_0[i][j]= R[omega_A[0][i],omega_M[0][j]]\n",
    "\n",
    "R_k_1 =np.zeros((len(omega_A[1]),len(omega_M[1])))\n",
    "for i in range(len(omega_A[1])):\n",
    "    for j in range(len(omega_M[1])):\n",
    "        R_k_1[i][j]= R[omega_A[1][i],omega_M[1][j]]\n",
    "        \n",
    "R_k_2 =np.zeros((len(omega_A[2]),len(omega_M[2])))\n",
    "for i in range(len(omega_A[2])):\n",
    "    for j in range(len(omega_M[2])):\n",
    "        R_k_2[i][j]= R[omega_A[2][i],omega_M[2][j]]\n",
    "        \n",
    "R_k_3 =np.zeros((len(omega_A[3]),len(omega_M[3])))\n",
    "for i in range(len(omega_A[3])):\n",
    "    for j in range(len(omega_M[3])):\n",
    "        R_k_3[i][j]= R[omega_A[3][i],omega_M[3][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label0=omega_M[0]\n",
    "label1=omega_M[1]\n",
    "label2=omega_M[2]\n",
    "label3=omega_M[3]\n",
    "\n",
    "index0=omega_A[0]\n",
    "index1=omega_A[1]\n",
    "index2=omega_A[2]\n",
    "index3=omega_A[3]\n",
    "A_hat_df = pd.DataFrame(A_hat,columns=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(R_k_0,columns=label0, index = index0).to_csv('Rp0.csv')\n",
    "pd.DataFrame(R_k_1,columns=label1, index = index1).to_csv('Rp1.csv')\n",
    "pd.DataFrame(R_k_2,columns=label2, index = index2).to_csv('Rp2.csv')\n",
    "pd.DataFrame(R_k_3,columns=label3, index = index3).to_csv('Rp3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sa = np.count_nonzero(R_sa)\n",
    "m_sa,n_sa = R_sa.shape\n",
    "\n",
    "c0=np.count_nonzero(R_k_0)\n",
    "c1=np.count_nonzero(R_k_1)\n",
    "c2=np.count_nonzero(R_k_2)\n",
    "c3=np.count_nonzero(R_k_3)\n",
    "m0,n0=R_k_0.shape\n",
    "m1,n1=R_k_1.shape\n",
    "m2,n2=R_k_2.shape\n",
    "m3,n3=R_k_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_sa-(c0+c1+c2+c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((m_sa*n_sa) - ((m0*n0)+(m1*n1)+(m2*n2)+(m3*n3)))/(m_sa*n_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the indices of users that have the feature of k=0\n",
    "omega_A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is indices of the movies or items in our data set that have the feature k = 0\n",
    "omega_M[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_k_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing user-genre matrix, that indicates how much each user likes a genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "m_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url']\n",
    "m_g_cols = ['movie_id', 'title', 'release_date', 'video_release_date', 'imdb_url', 'unknown', 'Action', 'Adventure', 'Animation'\n",
    "           , 'Children', 'Comedy','Crime', 'Documentary', 'Drama', 'Fantasy'\n",
    "           , 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "\n",
    "data_set_path_users = \"InputData/ml-100k/u.user\"\n",
    "data_set_path_ratings = \"InputData/ml-100k/u.data\"\n",
    "data_set_path_movies = \"InputData/ml-100k/u.item\"\n",
    "users = pd.read_csv(data_set_path_users,sep='|',names = u_cols)\n",
    "ratings = pd.read_csv(data_set_path_ratings,sep='\\t', names = r_cols).drop('timestamp',axis=1)\n",
    "movies = pd.read_csv(data_set_path_movies, sep='|', names = m_cols, usecols=range(5))\n",
    "movies_genre_df = pd.read_csv(data_set_path_movies, sep='|', names = m_g_cols).drop(['title', 'release_date', 'video_release_date', 'imdb_url'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the user demographic data\n",
    "user_data = pd.read_csv(data_set_path_users, sep='|', names=['user_id', 'age', 'sex', 'occupation', 'zip_code'], engine='python')\n",
    "\n",
    "# Display the first few rows to confirm we have the correct data this time\n",
    "user_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(users[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(users['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.sort_values(by='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[users['user_id'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings.sort_values('user_id')\n",
    "ratings[ratings['user_id'] == 1].sort_values('rating',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies['movie_id'] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_genre_df[movies_genre_df['movie_id'] == 170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_genre_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = np.array(pd.read_csv('InputData/R.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input function directly from numpy array.\n",
    "R_u, R_i = ratings.nonzero()\n",
    "R_s = ratings[ratings.nonzero()]\n",
    "train_data = tf.data.Dataset.from_tensor_slices(\n",
    "  ({\"user\": R_u, \"item\": R_i}, R_s))\n",
    "train_data = train_data.shuffle(buffer_size=1000).repeat(count=None).batch(1)\n",
    "\n",
    "# Build the factorization network.\n",
    "class KerasMF:\n",
    "\n",
    "  def __init__(self, R, k=3, l2=1e-4, with_bias=False):\n",
    "    self.l2_reg = tf.keras.regularizers.l2(l2)\n",
    "    self.m, self.n = R.shape\n",
    "    self.k = k\n",
    "    self.with_bias = with_bias\n",
    "    self.model = self.create_model()\n",
    "\n",
    "  def create_model(self):\n",
    "    user_inputs = tf.keras.layers.Input(shape=(1,), name=\"user\")\n",
    "    item_inputs = tf.keras.layers.Input(shape=(1,), name=\"item\")\n",
    "    user_embeddings = tf.keras.layers.Embedding(\n",
    "      input_dim=self.m, output_dim=self.k, name=\"user_embedding\",\n",
    "      embeddings_regularizer=self.l2_reg)(user_inputs)\n",
    "    item_embeddings = tf.keras.layers.Embedding(\n",
    "      input_dim=self.n, output_dim=self.k, name=\"item_embedding\",\n",
    "      embeddings_regularizer=self.l2_reg)(item_inputs)\n",
    "    dots = tf.keras.layers.Dot(axes=-1, name=\"logits\")([user_embeddings, item_embeddings])\n",
    "    if self.with_bias:\n",
    "      # The formal use of bias need a tf.keras.layers.Dense layer.\n",
    "      # But since we are customizing our network architecture,\n",
    "      # we will use the tf.keras.layers.Embedding layer to do the trick.\n",
    "      user_biases = tf.keras.layers.Embedding(\n",
    "        input_dim=self.m, output_dim=1, name=\"user_bias\")(user_inputs)\n",
    "      item_biases = tf.keras.layers.Embedding(\n",
    "        input_dim=self.n, output_dim=1, name=\"item_bias\")(item_inputs)\n",
    "      dots = tf.keras.layers.Add()([dots, user_biases, item_biases])\n",
    "    model = tf.keras.Model(\n",
    "      name=\"matrix_factorizer\",\n",
    "      inputs=[user_inputs, item_inputs], outputs=dots)\n",
    "    model.compile(\n",
    "      optimizer=tf.keras.optimizers.SGD(),\n",
    "      loss=tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[\n",
    "        tf.keras.metrics.MeanSquaredError()\n",
    "      ]\n",
    "    )\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "keras_mf = KerasMF(R=ratings, with_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_mf.model.fit(train_data, epochs=10, steps_per_epoch=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_preds = keras_mf.model.predict({\"user\": R_u, \"item\": R_i})\n",
    "print(np.stack([np.squeeze(keras_preds),\n",
    "               ratings[ratings.nonzero()]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BinarizingA: Tresholding via perventile (Great result, 40% of two_user accounts were identified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_hat_B = (U.value > np.percentile(U.value, 70)).astype(int)  # Using a percentile threshold\n",
    "n_identified = A_hat_B.sum()\n",
    "n_identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BinarizingA: Clustering (Terrible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the continuous solution for U\n",
    "U_continuous = U.value\n",
    "\n",
    "# Apply k-means clustering to binarize U\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(U_continuous)\n",
    "labels = kmeans.labels_  # Labels for rows, each label applies to all features of the row\n",
    "\n",
    "# Expand labels to all features in U\n",
    "U_binary = np.array([labels] * k).T  # Transpose to match the shape of U\n",
    "\n",
    "print(\"Binarized U matrix based on k-means clustering:\")\n",
    "print(U_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clusters labels as 0 or 1, which directly gives us the binary matrix\n",
    "# If needed, map clusters to 0 and 1 based on centroids if not already so\n",
    "centroids = kmeans.cluster_centers_\n",
    "if np.mean(centroids[0]) > np.mean(centroids[1]):\n",
    "    U_binary = 1 - U_binary  # Invert labels if 0 is closer to the higher centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the continuous solution for U\n",
    "U_continuous = U.value\n",
    "\n",
    "# Apply k-means clustering to binarize U\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(U_continuous)\n",
    "labels = kmeans.labels_  # Labels for rows, each label applies to all features of the row\n",
    "centroids = kmeans.cluster_centers_  # Centroids of the clusters\n",
    "\n",
    "# Determine which label corresponds to the higher and lower centroid\n",
    "label_high = 0 if centroids[0].mean() > centroids[1].mean() else 1\n",
    "\n",
    "# Create binary matrix based on the label associated with the higher centroid\n",
    "U_binary = np.where(labels[:, None] == label_high, 1, 0)\n",
    "\n",
    "print(\"Centroids:\", centroids)\n",
    "print(\"Label associated with the higher centroid:\", label_high)\n",
    "print(\"Binarized U matrix based on k-means clustering:\")\n",
    "print(U_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_identified = U_binary.sum()\n",
    "n_identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 637\n",
    "print(np.round(softmax(U_continuous)[a],4))\n",
    "print(np.round(U_continuous[a],4))\n",
    "print(A_hat_B[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_softened_3 = np.reshape(softmax(U.value, temperature=2),(784,4))\n",
    "A_softened_0 = np.reshape(softmax(U.value, temperature=0.5),(784,4))\n",
    "A_hat_B_softened_3 = project_onto_face(A_softened_3,l = 0.9931)\n",
    "A_hat_B_softened_0 = project_onto_face(A_softened_0,l = 0.9727)\n",
    "\n",
    "print(A_hat_B_softened_3.sum())\n",
    "print(A_hat_B_softened_0.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('softened_3',UserIdentificationMeasure(SA,A_hat_B_softened_3)[2])\n",
    "print('softened_0',UserIdentificationMeasure(SA,A_hat_B_softened_0)[2])\n",
    "print('B_abs',UserIdentificationMeasure(SA,A_hat_B_abs)[2])\n",
    "print('A_hat_B',UserIdentificationMeasure(SA,A_hat_B)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lA = 0.5189\n",
    "A_hat_B_abs = project_onto_face(np.abs(U.value),lA)  # Using a percentile threshold\n",
    "\n",
    "n_identified = A_hat_B.sum()\n",
    "n_identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Constants for the dimensions of the matrices\n",
    "# m, k, n = 784, 4, 1680  # m x k (U), k x n (V), m x n (R)\n",
    "\n",
    "m, n = R_sa.shape   # Number of accounts and movies\n",
    "O = np.array(R_sa != 0,dtype='float')   # Producing Observation matrix \n",
    "k = M.shape[0]   # Number of features\n",
    "\n",
    "R = R_sa.astype(np.float32)  # Example rating matrix R\n",
    "V = M.astype(np.float32)  # Known item feature matrix V\n",
    "\n",
    "V_constant = cp.Parameter((k, n), value=V)\n",
    "\n",
    "U = cp.Variable((m, k), nonneg=True)  # Ensures U is non-negative\n",
    "\n",
    "objective = cp.Minimize(cp.norm(R - cp.multiply(O,(U @ V_constant)), 'fro') + 0.1 * cp.norm(U, 1))\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "problem = cp.Problem(objective)\n",
    "result = problem.solve(solver=cp.SCS)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Optimal value (loss):\", result)\n",
    "print(\"Learned matrix U with non-negativity constraint:\", U.value)\n",
    "print(\"Computation Time: {:.2f} seconds\".format(end_time - start_time))\n",
    "\n",
    "# A_hat_B = project_onto_face(A, l=0.44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# آیا شافل شدن ردیف های ماتریس آر هم در خطای توصیه گر تاثیر داره؟\n",
    "در فرایند محاسبه خود خطا که نداره،\n",
    "اما در فرایند برآورد هر کدام از رتبه ها احتمالن داره با توجه به روش توصیه گر"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original R:\n",
      "[[0. 5. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [7. 4. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Newly shuffled R:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 3. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 3. 0. ... 0. 0. 0.]\n",
      " [5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "shuffled_R_sa = R_sa[np.random.permutation(R_sa.shape[0]), :]\n",
    "print(\"Original R:\")\n",
    "print(R_sa)\n",
    "print(\"Newly shuffled R:\")\n",
    "print(shuffled_R_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2509051327077652"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComputeRMSE(R_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.251690344110006"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComputeRMSE(shuffled_R_sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ببینیم توصیه گر برای هر کاربر  چه توصیه هایی میکنه"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ratings for user A: {'1': 3.0013339098361467, '2': 2.910688876607268, '3': 3.0890550195012}\n",
      "Estimated ratings for user A: {'1': 2.983929999800422, '2': 2.711401758551493, '3': 3.2430041025043463}\n",
      "Estimated ratings for unrated items for user A: {}\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Sample data: user, item, rating\n",
    "data = {\n",
    "    'userID': ['A', 'A', 'A', 'B', 'B', 'C'],\n",
    "    'itemID': ['1', '2', '3', '1', '3', '2'],\n",
    "    'rating': [3, 2, 4, 2, 5, 3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a reader with the rating scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load the dataset from the dataframe\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Use the SVD algorithm, similar to Singular Value Decomposition in Matrix Factorization\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "# Assuming you want to predict ratings for user 'A' for all items in the dataset\n",
    "user_id = 0\n",
    "items = df['itemID'].unique()  # All unique items\n",
    "\n",
    "# Dictionary to store the predicted ratings\n",
    "predicted_ratings = {}\n",
    "\n",
    "for item_id in items:\n",
    "    # Predict rating for each item\n",
    "    prediction = model.predict(user_id, item_id)\n",
    "    predicted_ratings[item_id] = prediction.est\n",
    "\n",
    "print(\"Estimated ratings for user A:\", predicted_ratings)\n",
    "\n",
    "\n",
    "# Assuming you want to predict ratings for user 'A' for all items in the dataset\n",
    "user_id = 'A'\n",
    "items = df['itemID'].unique()  # All unique items\n",
    "\n",
    "# Dictionary to store the predicted ratings\n",
    "predicted_ratings = {}\n",
    "\n",
    "for item_id in items:\n",
    "    # Predict rating for each item\n",
    "    prediction = model.predict(user_id, item_id)\n",
    "    predicted_ratings[item_id] = prediction.est\n",
    "\n",
    "print(\"Estimated ratings for user A:\", predicted_ratings)\n",
    "\n",
    "\n",
    "# Items that user 'A' has rated\n",
    "rated_items = df[df['userID'] == user_id]['itemID'].unique()\n",
    "\n",
    "# Predict ratings for unrated items only\n",
    "predicted_ratings = {}\n",
    "for item_id in items:\n",
    "    if item_id not in rated_items:\n",
    "        prediction = model.predict(user_id, item_id)\n",
    "        predicted_ratings[item_id] = prediction.est\n",
    "\n",
    "print(\"Estimated ratings for unrated items for user A:\", predicted_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 5, 0, 0]), array([ 0,  1,  0,  0, 10,  0]))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example Data\n",
    "v = np.array([0, 1, 0, 5, 10, 0])  # Combined vector\n",
    "a = 1  # Weight for c1\n",
    "b = 1  # Weight for c2\n",
    "\n",
    "# Assuming we know the non-overlapping indices:\n",
    "# c1 is non-zero only at index 3, and c2 is non-zero at indices 1 and 4\n",
    "c1_indices = [3]  # Example indices for c1\n",
    "c2_indices = [1, 4]  # Example indices for c2\n",
    "\n",
    "# Initialize c1 and c2 as zeros\n",
    "c1 = np.zeros_like(v)\n",
    "c2 = np.zeros_like(v)\n",
    "\n",
    "# Calculate c1 and c2 based on non-overlapping assumption\n",
    "c1[c1_indices] = v[c1_indices] / a\n",
    "c2[c2_indices] = v[c2_indices] / b\n",
    "\n",
    "# Output the vectors\n",
    "c1, c2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
